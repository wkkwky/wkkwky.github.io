# ã€ç¬”è®°ã€‘Sturctured Streamingç¬”è®°æ€»ç»“ï¼ˆPythonç‰ˆï¼‰


# **ç›®å½•**
- [ç›¸å…³èµ„æ–™](#ç›¸å…³èµ„æ–™)
  - [æœ¬æ–‡ç›¸å…³ä»£ç ](#æœ¬æ–‡ç›¸å…³ä»£ç )
- [ä¸€ã€æ¦‚è¿°](#ä¸€æ¦‚è¿°)
  - [1.1 åŸºæœ¬æ¦‚å¿µ](#11-åŸºæœ¬æ¦‚å¿µ)
  - [1.2 ä¸¤ç§å¤„ç†æ¨¡å‹](#12-ä¸¤ç§å¤„ç†æ¨¡å‹)
    - [ï¼ˆ1ï¼‰å¾®æ‰¹å¤„ç†](#1å¾®æ‰¹å¤„ç†)
    - [ï¼ˆ2ï¼‰æŒç»­å¤„ç†](#2æŒç»­å¤„ç†)
  - [1.3 Structured Streamingå’ŒSpark SQLã€Spark Streamingå…³ç³»](#13-structured-streamingå’Œspark-sqlspark-streamingå…³ç³»)
- [äºŒã€ç¼–å†™Structured Streamingç¨‹åºçš„åŸºæœ¬æ­¥éª¤](#äºŒç¼–å†™structured-streamingç¨‹åºçš„åŸºæœ¬æ­¥éª¤)
- [ä¸‰ã€è¾“å…¥æº](#ä¸‰è¾“å…¥æº)
  - [3.1 Fileæº](#31-fileæº)
    - [ï¼ˆ1ï¼‰åˆ›å»ºç¨‹åºç”ŸæˆJSONæ ¼å¼çš„Fileæºæµ‹è¯•æ•°æ®](#1åˆ›å»ºç¨‹åºç”Ÿæˆjsonæ ¼å¼çš„fileæºæµ‹è¯•æ•°æ®)
    - [ï¼ˆ2ï¼‰åˆ›å»ºç¨‹åºå¯¹æ•°æ®è¿›è¡Œç»Ÿè®¡](#2åˆ›å»ºç¨‹åºå¯¹æ•°æ®è¿›è¡Œç»Ÿè®¡)
    - [ï¼ˆ3ï¼‰æµ‹è¯•è¿è¡Œç¨‹åº](#3æµ‹è¯•è¿è¡Œç¨‹åº)
    - [ï¼ˆ4ï¼‰å¤„ç†è­¦å‘Š](#4å¤„ç†è­¦å‘Š)
    - [ï¼ˆ5ï¼‰æ€»ç»“åˆ†æ](#5æ€»ç»“åˆ†æ)
  - [3.2 Kafkaæº](#32-kafkaæº)
    - [ï¼ˆ1ï¼‰å¯åŠ¨Kafka](#1å¯åŠ¨kafka)
    - [ï¼ˆ2ï¼‰ç¼–å†™ç”Ÿäº§è€…ï¼ˆProducerï¼‰ç¨‹åº](#2ç¼–å†™ç”Ÿäº§è€…producerç¨‹åº)
    - [ï¼ˆ3ï¼‰å®‰è£…Python3çš„Kafkaæ”¯æŒ](#3å®‰è£…python3çš„kafkaæ”¯æŒ)
    - [ï¼ˆ4ï¼‰è¿è¡Œç”Ÿäº§è€…ç¨‹åº](#4è¿è¡Œç”Ÿäº§è€…ç¨‹åº)
    - [ï¼ˆ5ï¼‰ç¼–å†™å¹¶è¿è¡Œæ¶ˆè´¹è€…ï¼ˆConsumerï¼‰ç¨‹åº](#5ç¼–å†™å¹¶è¿è¡Œæ¶ˆè´¹è€…consumerç¨‹åº)
      - [æ–¹å¼ä¸€](#æ–¹å¼ä¸€)
      - [æ–¹å¼äºŒ](#æ–¹å¼äºŒ)
    - [æ€»ç»“](#æ€»ç»“)
  - [3.3 Socketæº](#33-socketæº)
  - [3.4 Rateæº](#34-rateæº)

------



# ç›¸å…³èµ„æ–™

1. [å¦å¤§ Kafkaå’ŒStructured Streamingçš„ç»„åˆä½¿ç”¨ï¼ˆScalaç‰ˆï¼‰](https://dblab.xmu.edu.cn/blog/3160/)

2. [Structured Streaming + Kafkaé›†æŒ‡å—](https://spark.apache.org/docs/3.2.0/structured-streaming-kafka-integration.html)

3. [Pysparkæ‰‹å†ŒDataStreamReader](https://spark.apache.org/docs/3.2.0/api/python/reference/api/pyspark.sql.streaming.DataStreamReader.html#pyspark.sql.streaming.DataStreamReader)

4. [Kafkaå®‰è£…æ•™ç¨‹](https://blog.csdn.net/qq_67822268/article/details/138626412)

5. [Mavenä¸­å¤®ä»“åº“](https://repo1.maven.org/maven2/)

6. [Maven Repository](https://mvnrepository.com/)

7. [kafka-pythonæ–‡æ¡£](https://kafka-python.readthedocs.io/en/master/index.html)

8. [strcuted streaming OutputModeè®²è§£](https://www.jianshu.com/p/ed1398c2470a))

------

## æœ¬æ–‡ç›¸å…³ä»£ç 

æœ¬æ–‡ç›¸å…³ä»£ç è¯»è€…å¯ä»¥è‡ªè¡Œä¸‹è½½ï¼š

é“¾æ¥ï¼š[https://pan.baidu.com/s/121zVsgc4muSt9rgCWnJZmw](https://pan.baidu.com/s/121zVsgc4muSt9rgCWnJZmw)

æå–ç ï¼šwkk6

------

# ä¸€ã€æ¦‚è¿°

## 1.1 åŸºæœ¬æ¦‚å¿µ

Structured Streaming æ˜¯ Apache Spark æä¾›çš„ä¸€ç§æµå¤„ç†å¼•æ“ï¼Œå®ƒåŸºäº Spark SQL å¼•æ“ï¼Œå¹¶æä¾›äº†æ›´é«˜çº§åˆ«ã€æ›´æ˜“ç”¨çš„ APIï¼Œä½¿å¾—å¤„ç†å®æ—¶æ•°æ®æµå˜å¾—æ›´åŠ ç®€å•å’Œç›´è§‚ã€‚

 Structured Streaming çš„ä¸€äº›ç‰¹ç‚¹å’Œä¼˜åŠ¿ï¼š

1. **åŸºäº DataFrame å’Œ Dataset API**ï¼šStructured Streaming æ„å»ºåœ¨ Spark çš„ DataFrame å’Œ Dataset API ä¹‹ä¸Šï¼Œä½¿å¾—å¯¹æµæ•°æ®çš„å¤„ç†ä¸æ‰¹å¤„ç†éå¸¸ç±»ä¼¼ï¼Œé™ä½äº†å­¦ä¹ æˆæœ¬ã€‚
2. **å®¹é”™æ€§**ï¼šStructured Streaming æä¾›ç«¯åˆ°ç«¯çš„å®¹é”™ä¿è¯ï¼ˆæŒ‡åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œæ•´ä¸ªæ•°æ®å¤„ç†æµç¨‹ä»æ•°æ®è¾“å…¥åˆ°è¾“å‡ºçš„å…¨è¿‡ç¨‹éƒ½èƒ½å¤Ÿä¿è¯å®¹é”™æ€§ã€‚æ¢å¥è¯è¯´ï¼Œæ— è®ºæ˜¯æ•°æ®çš„æ¥æ”¶ã€å¤„ç†è¿˜æ˜¯è¾“å‡ºï¼Œç³»ç»Ÿéƒ½èƒ½å¤Ÿåœ¨å‘ç”Ÿæ•…éšœæˆ–å¼‚å¸¸æƒ…å†µæ—¶ä¿æŒæ•°æ®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§ï¼‰ï¼Œèƒ½å¤Ÿç¡®ä¿åœ¨å‘ç”Ÿæ•…éšœæ—¶ä¸ä¼šä¸¢å¤±æ•°æ®ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¿è¯ç²¾ç¡®ä¸€æ¬¡å¤„ç†è¯­ä¹‰ã€‚
3. **é«˜æ€§èƒ½**ï¼šStructured Streaming å……åˆ†åˆ©ç”¨äº† Spark å¼•æ“çš„ä¼˜åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿè¿›è¡ŒæŸ¥è¯¢ä¼˜åŒ–ã€çŠ¶æ€ç®¡ç†å’Œåˆ†å¸ƒå¼å¤„ç†ï¼Œä»è€Œæä¾›é«˜æ€§èƒ½çš„å®æ—¶å¤„ç†èƒ½åŠ›ã€‚
4. **çµæ´»çš„äº‹ä»¶æ—¶é—´å¤„ç†**ï¼šStructured Streaming æ”¯æŒäº‹ä»¶æ—¶é—´ï¼ˆevent-timeï¼‰å¤„ç†ï¼Œå¯ä»¥è½»æ¾å¤„ç†ä¹±åºäº‹ä»¶ã€å»¶è¿Ÿäº‹ä»¶ç­‰åœºæ™¯ï¼Œå¹¶æä¾›ä¸°å¯Œçš„çª—å£æ“ä½œæ”¯æŒã€‚
5. **é›†æˆæ€§**ï¼šStructured Streaming æä¾›äº†ä¸å„ç§æ•°æ®æºçš„é›†æˆï¼ŒåŒ…æ‹¬ Kafkaã€Flumeã€HDFSã€S3 ç­‰ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒå°†ç»“æœå†™å…¥å„ç§å­˜å‚¨ç³»ç»Ÿã€‚
6. **æ˜“äºè°ƒè¯•å’Œç›‘æ§**ï¼šStructured Streaming æä¾›äº†ä¸°å¯Œçš„ç›‘æ§å’Œè°ƒè¯•åŠŸèƒ½ï¼ŒåŒ…æ‹¬è¿›åº¦æŠ¥å‘Šã€çŠ¶æ€æŸ¥è¯¢ç­‰ï¼Œæ–¹ä¾¿ç”¨æˆ·ç›‘æ§ä½œä¸šçš„æ‰§è¡Œæƒ…å†µã€‚

Structured Streamingçš„å…³é”®æ€æƒ³æ˜¯å°†å®æ—¶æ•°æ®æµè§†ä¸ºä¸€å¼ æ­£åœ¨ä¸æ–­æ·»åŠ æ•°æ®çš„è¡¨

å¯ä»¥æŠŠæµè®¡ç®—ç­‰åŒäºåœ¨ä¸€ä¸ªé™æ€è¡¨ä¸Šçš„æ‰¹å¤„ç†æŸ¥è¯¢ï¼ŒSparkä¼šåœ¨ä¸æ–­æ·»åŠ æ•°æ®çš„<font color=red>æ— ç•Œè¾“å…¥è¡¨</font>ä¸Šè¿è¡Œè®¡ç®—ï¼Œå¹¶è¿›è¡Œå¢é‡æŸ¥è¯¢

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89d5876f258f6047008124740891399f9b.png)

åœ¨æ— ç•Œè¡¨ä¸Šå¯¹è¾“å…¥çš„æŸ¥è¯¢å°†ç”Ÿæˆç»“æœè¡¨ï¼Œç³»ç»Ÿæ¯éš”ä¸€å®šçš„å‘¨æœŸä¼šè§¦å‘å¯¹<font color=red>æ— ç•Œè¡¨</font>çš„è®¡ç®—å¹¶æ›´æ–°ç»“æœè¡¨

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%890f5792abddf5eb8e3f9103e8412e49c5.png)

## 1.2 ä¸¤ç§å¤„ç†æ¨¡å‹

### ï¼ˆ1ï¼‰å¾®æ‰¹å¤„ç†

Structured Streaming<font color=red>é»˜è®¤</font>ä½¿ç”¨å¾®æ‰¹å¤„ç†æ‰§è¡Œæ¨¡å‹ï¼Œè¿™æ„å‘³ç€Sparkæµè®¡ç®—å¼•æ“ä¼šå®šæœŸæ£€æŸ¥æµæ•°æ®æºï¼Œå¹¶å¯¹è‡ªä¸Šä¸€æ‰¹æ¬¡ç»“æŸååˆ°è¾¾çš„<font color=red>æ–°æ•°æ®</font>æ‰§è¡Œæ‰¹é‡æŸ¥è¯¢

æ•°æ®åˆ°è¾¾å’Œå¾—åˆ°å¤„ç†å¹¶è¾“å‡ºç»“æœä¹‹é—´çš„å»¶æ—¶<font color=ï¼ƒ00FFFF>è¶…è¿‡100æ¯«ç§’</font>

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89574c1d8809c4e9890f6dbeb04d830629.png)

åœ¨è¿™é‡Œï¼Œå›ç­”ä¸‰ä¸ªé—®é¢˜ï¼š

1.ä»€ä¹ˆæ˜¯åç§»é‡ï¼Ÿ

åœ¨ Structured Streaming ä¸­ï¼Œåç§»é‡ï¼ˆOffsetï¼‰æ˜¯æŒ‡ç”¨äºæ ‡è¯†æ•°æ®æµä¸­ä½ç½®çš„æ ‡è®°ï¼Œå®ƒè¡¨ç¤ºäº†æ•°æ®æµä¸­çš„ä¸€ä¸ªç‰¹å®šä½ç½®æˆ–è€…åç§»é‡ã€‚åœ¨æµå¤„ç†ä¸­ï¼Œåç§»é‡é€šå¸¸ç”¨äºè®°å½•å·²ç»å¤„ç†çš„æ•°æ®ä½ç½®ï¼Œä»¥ä¾¿åœ¨å¤±è´¥æ¢å¤ã€æ–­ç‚¹ç»­ä¼ æˆ–è€…çŠ¶æ€ç®¡ç†ç­‰åœºæ™¯ä¸‹èƒ½å¤Ÿå‡†ç¡®åœ°ä»ä¸­æ–­å¤„ç»§ç»­å¤„ç†æ•°æ®ã€‚

å…·ä½“æ¥è¯´ï¼Œåœ¨ç»“æ„åŒ–æµå¤„ç†ä¸­ï¼Œåç§»é‡é€šå¸¸ä¸è¾“å…¥æ•°æ®æºç´§å¯†ç›¸å…³ï¼Œæ¯”å¦‚ Kafkaã€File Source ç­‰ã€‚å½“ Spark ç»“æ„åŒ–æµå¯åŠ¨æ—¶ï¼Œä¼šä»æ•°æ®æºä¸­è¯»å–åç§»é‡ï¼Œå¹¶ä½¿ç”¨è¿™äº›åç§»é‡æ¥ç¡®å®šåº”è¯¥ä»å“ªé‡Œå¼€å§‹è¯»å–æ•°æ®ã€‚éšç€æ•°æ®è¢«å¤„ç†ï¼ŒSpark ä¼šä¸æ–­æ›´æ–°åç§»é‡ï¼Œä»¥ç¡®ä¿åœ¨å‘ç”Ÿæ•…éšœæˆ–é‡å¯æƒ…å†µä¸‹èƒ½å¤Ÿå‡†ç¡®åœ°æ¢å¤åˆ°ä¹‹å‰å¤„ç†çš„ä½ç½®ã€‚

2.ä¸ºä»€ä¹ˆè¦è®°å½•åç§»é‡ï¼Ÿ

- **å®¹é”™å’Œæ•…éšœæ¢å¤**ï¼šè®°å½•åç§»é‡å¯ä»¥ç¡®ä¿åœ¨æµå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæ•…éšœæˆ–è€…éœ€è¦é‡å¯æ—¶èƒ½å¤Ÿå‡†ç¡®åœ°æ¢å¤åˆ°ä¹‹å‰å¤„ç†çš„ä½ç½®ï¼Œé¿å…æ•°æ®çš„ä¸¢å¤±å’Œé‡å¤å¤„ç†ã€‚é€šè¿‡è®°å½•åç§»é‡ï¼Œæµå¤„ç†ç³»ç»Ÿèƒ½å¤ŸçŸ¥é“ä»å“ªé‡Œç»§ç»­è¯»å–æ•°æ®ï¼Œä»è€Œä¿è¯æ•°æ®å¤„ç†çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§ã€‚
- **ç²¾ç¡®ä¸€æ¬¡å¤„ç†è¯­ä¹‰**ï¼šè®°å½•åç§»é‡ä¹Ÿæœ‰åŠ©äºå®ç°ç²¾ç¡®ä¸€æ¬¡å¤„ç†è¯­ä¹‰ï¼Œå³ç¡®ä¿æ¯æ¡è¾“å…¥æ•°æ®åªè¢«å¤„ç†ä¸€æ¬¡ã€‚é€šè¿‡å‡†ç¡®è®°å½•åç§»é‡å¹¶åœ¨å‘ç”Ÿæ•…éšœåèƒ½å¤Ÿå‡†ç¡®åœ°æ¢å¤åˆ°ä¹‹å‰çš„ä½ç½®ï¼Œæµå¤„ç†ç³»ç»Ÿèƒ½å¤Ÿé¿å…é‡å¤å¤„ç†æ•°æ®ï¼Œä»è€Œç¡®ä¿å¤„ç†ç»“æœçš„å‡†ç¡®æ€§ã€‚
- **æ–­ç‚¹ç»­ä¼ **ï¼šè®°å½•åç§»é‡è¿˜ä½¿å¾—æµå¤„ç†ç³»ç»Ÿèƒ½å¤Ÿæ”¯æŒæ–­ç‚¹ç»­ä¼ çš„åŠŸèƒ½ï¼Œå³åœ¨æµå¤„ç†è¿‡ç¨‹ä¸­å¯ä»¥éšæ—¶åœæ­¢ï¼Œå¹¶åœ¨ä¹‹åæ¢å¤åˆ°ä¹‹å‰çš„å¤„ç†ä½ç½®ï¼Œè€Œä¸éœ€è¦é‡æ–°å¤„ç†ä¹‹å‰å·²ç»å¤„ç†è¿‡çš„æ•°æ®ã€‚

é€šè¿‡è®°å½•åç§»é‡ï¼Œç»“æ„åŒ–æµå¤„ç†å¯ä»¥å®ç°ç²¾ç¡®ä¸€æ¬¡å¤„ç†è¯­ä¹‰ï¼Œå¹¶ç¡®ä¿å³ä½¿åœ¨å‡ºç°æ•…éšœå’Œé‡å¯çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å¤Ÿä¿è¯æ•°æ®ä¸ä¼šè¢«é‡å¤å¤„ç†æˆ–ä¸¢å¤±ã€‚å› æ­¤ï¼Œåç§»é‡åœ¨ç»“æ„åŒ–æµå¤„ç†ä¸­æ‰®æ¼”ç€éå¸¸é‡è¦çš„è§’è‰²ï¼Œæ˜¯å®ç°æµå¤„ç†çš„å®¹é”™æ€§å’Œå‡†ç¡®æ€§çš„å…³é”®ä¹‹ä¸€ã€‚

å…³äºåç§»é‡çš„ç†è§£ï¼Œå¯ä»¥å‚è€ƒï¼š[å…³äºåç§»é‡çš„ç†è§£-CSDNåšå®¢](https://blog.csdn.net/u011641620/article/details/15963851)

3.ä¸ºä»€ä¹ˆå»¶æ—¶è¶…è¿‡100æ¯«ç§’ï¼Ÿ

Driver é©±åŠ¨ç¨‹åºé€šè¿‡å°†å½“å‰å¾…å¤„ç†æ•°æ®çš„åç§»é‡<font color=red>ä¿å­˜åˆ°é¢„å†™æ—¥å¿—</font>ä¸­ï¼Œæ¥å¯¹æ•°æ®å¤„ç†è¿›åº¦è®¾ç½®æ£€æŸ¥ç‚¹ï¼Œä»¥ä¾¿ä»Šåå¯ä»¥ä½¿ç”¨å®ƒæ¥é‡æ–°å¯åŠ¨æˆ–æ¢å¤æŸ¥è¯¢ã€‚

ä¸ºäº†è·å¾—ç¡®å®šæ€§çš„é‡æ–°æ‰§è¡Œï¼ˆDeterministic Re-executionsï¼‰å’Œç«¯åˆ°ç«¯è¯­ä¹‰ï¼Œåœ¨ä¸‹ä¸€ä¸ªå¾®æ‰¹å¤„ç†ä¹‹å‰ï¼Œå°±è¦å°†è¯¥å¾®æ‰¹å¤„ç†æ‰€è¦å¤„ç†çš„æ•°æ®çš„åç§»èŒƒå›´ä¿å­˜åˆ°æ—¥å¿—ä¸­ã€‚æ‰€ä»¥ï¼Œå½“å‰åˆ°è¾¾çš„æ•°æ®éœ€è¦ç­‰å¾…å…ˆå‰çš„å¾®æ‰¹ä½œä¸šå¤„ç†å®Œæˆï¼Œ<font color=red>ä¸”</font>å®ƒçš„åç§»é‡èŒƒå›´è¢«è®°å…¥æ—¥å¿—åï¼Œæ‰èƒ½åœ¨ä¸‹ä¸€ä¸ªå¾®æ‰¹ä½œä¸šä¸­å¾—åˆ°å¤„ç†ï¼Œè¿™ä¼šå¯¼è‡´æ•°æ®åˆ°è¾¾å’Œå¾—åˆ°å¤„ç†å¹¶è¾“å‡ºç»“æœä¹‹é—´çš„å»¶æ—¶è¶…è¿‡100æ¯«ç§’ã€‚

### ï¼ˆ2ï¼‰æŒç»­å¤„ç†

å¾®æ‰¹å¤„ç†çš„æ•°æ®å»¶è¿Ÿå¯¹äºå¤§å¤šæ•°å®é™…çš„æµå¼å·¥ä½œè´Ÿè½½ï¼ˆå¦‚ETLå’Œç›‘æ§ï¼‰å·²ç»è¶³å¤Ÿäº†ï¼Œç„¶è€Œï¼Œä¸€äº›åœºæ™¯ç¡®å®éœ€è¦<font color=red>æ›´ä½çš„å»¶è¿Ÿ</font>ã€‚æ¯”å¦‚ï¼Œåœ¨é‡‘èè¡Œä¸šçš„ä¿¡ç”¨å¡æ¬ºè¯ˆäº¤æ˜“è¯†åˆ«ä¸­ï¼Œéœ€è¦åœ¨çŠ¯ç½ªåˆ†å­ç›—åˆ·ä¿¡ç”¨å¡åç«‹åˆ»è¯†åˆ«å¹¶é˜»æ­¢ï¼Œä½†æ˜¯åˆä¸æƒ³è®©åˆæ³•äº¤æ˜“çš„ç”¨æˆ·æ„Ÿè§‰åˆ°å»¶è¿Ÿï¼Œä»è€Œå½±å“ç”¨æˆ·çš„ä½¿ç”¨ä½“éªŒï¼Œè¿™å°±éœ€è¦åœ¨ 10ï½20æ¯«ç§’çš„æ—¶é—´å†…å¯¹æ¯ç¬”äº¤æ˜“è¿›è¡Œæ¬ºè¯ˆè¯†åˆ«ï¼Œè¿™æ—¶å°±ä¸èƒ½ä½¿ç”¨å¾®æ‰¹å¤„ç†æ¨¡å‹ï¼Œè€Œéœ€è¦ä½¿ç”¨æŒç»­å¤„ç†æ¨¡å‹ã€‚


Sparkä»2.3.0ç‰ˆæœ¬å¼€å§‹å¼•å…¥äº†æŒç»­å¤„ç†çš„è¯•éªŒæ€§åŠŸèƒ½ï¼Œå¯ä»¥å®ç°æµè®¡ç®—çš„æ¯«ç§’çº§å»¶è¿Ÿã€‚

åœ¨æŒç»­å¤„ç†æ¨¡å¼ä¸‹ï¼ŒSparkä¸å†æ ¹æ®è§¦å‘å™¨æ¥å‘¨æœŸæ€§å¯åŠ¨ä»»åŠ¡ï¼Œè€Œæ˜¯å¯åŠ¨ä¸€ç³»åˆ—çš„è¿ç»­è¯»å–ã€å¤„ç†å’Œå†™å…¥ç»“æœçš„é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ã€‚

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89928f8f52e41e85ba707980a7437ec8fc.png)

ä¸ºäº†ç¼©çŸ­å»¶è¿Ÿï¼Œå¼•å…¥äº†æ–°çš„ç®—æ³•å¯¹æŸ¥è¯¢è®¾ç½®æ£€æŸ¥ç‚¹ï¼Œåœ¨æ¯ä¸ªä»»åŠ¡çš„è¾“å…¥æ•°æ®æµä¸­ï¼Œä¸€ä¸ªç‰¹æ®Šæ ‡è®°çš„è®°å½•è¢«æ³¨å…¥ã€‚å½“ä»»åŠ¡é‡åˆ°æ ‡è®°æ—¶ï¼Œä»»åŠ¡æŠŠå¤„ç†åçš„æœ€ååç§»é‡[å¼‚æ­¥](https://www.bilibili.com/video/BV1MC411a7rY/?share_source=copy_web&vd_source=4e01e9db7e3603b44b8d2cfb31455773)ï¼ˆä»»åŠ¡çš„æ‰§è¡Œä¸å¿…ç­‰å¾…å…¶ä»–ä»»åŠ¡å®Œæˆæˆ–æŸä¸ªäº‹ä»¶å‘ç”Ÿï¼‰åœ°æŠ¥å‘Šç»™å¼•æ“ï¼Œå¼•æ“æ¥æ”¶åˆ°æ‰€æœ‰å†™å…¥æ¥æ”¶å™¨çš„ä»»åŠ¡çš„åç§»é‡åï¼Œå†™å…¥é¢„å†™æ—¥å¿—ã€‚ç”±äºæ£€æŸ¥ç‚¹çš„å†™å…¥æ˜¯å®Œå…¨å¼‚æ­¥çš„ï¼Œä»»åŠ¡å¯ä»¥æŒç»­å¤„ç†ï¼Œå› æ­¤ï¼Œå»¶è¿Ÿå¯ä»¥ç¼©çŸ­åˆ°æ¯«ç§’çº§ã€‚ä¹Ÿæ­£æ˜¯ç”±äºå†™å…¥æ˜¯å¼‚æ­¥çš„ï¼Œä¼šå¯¼è‡´æ•°æ®æµåœ¨æ•…éšœåå¯èƒ½è¢«å¤„ç†è¶…è¿‡ä¸€æ¬¡ä»¥ä¸Šï¼Œæ‰€ä»¥ï¼ŒæŒç»­å¤„ç†åªèƒ½åšåˆ°â€œè‡³å°‘ä¸€æ¬¡â€çš„ä¸€è‡´æ€§ã€‚å› æ­¤ï¼Œéœ€è¦æ³¨æ„åˆ°ï¼Œè™½ç„¶æŒç»­å¤„ç†æ¨¡å‹èƒ½æ¯”å¾®æ‰¹å¤„ç†æ¨¡å‹è·å¾—æ›´å¥½çš„å®æ—¶å“åº”æ€§èƒ½ï¼Œä½†æ˜¯ï¼Œè¿™æ˜¯ä»¥ç‰ºç‰²ä¸€è‡´æ€§ä¸ºä»£ä»·çš„ã€‚å¾®æ‰¹å¤„ç†å¯ä»¥ä¿è¯ç«¯åˆ°ç«¯çš„å®Œå…¨ä¸€è‡´æ€§ï¼Œè€ŒæŒç»­å¤„ç†åªèƒ½åšåˆ°â€œè‡³å°‘ä¸€æ¬¡â€çš„ä¸€è‡´æ€§ã€‚



å¾®æ‰¹å¤„ç†å’ŒæŒç»­å¤„ç†æ˜¯æµå¤„ç†ä¸­ä¸¤ç§å¸¸è§çš„å¤„ç†æ¨¡å¼ï¼Œå°†ä»–ä»¬è¿›è¡Œå¯¹æ¯”ï¼š

1. **å¤„ç†æ–¹å¼**ï¼š
   - å¾®æ‰¹å¤„ç†ï¼ˆmicro-batch processingï¼‰ï¼šå°†è¿ç»­çš„æ•°æ®æµæŒ‰ç…§ä¸€å®šçš„æ—¶é—´é—´éš”æˆ–è€…æ•°æ®é‡åˆ’åˆ†æˆå°æ‰¹é‡è¿›è¡Œå¤„ç†ï¼Œæ¯ä¸ªæ‰¹é‡æ•°æ®è¢«è§†ä¸ºä¸€ä¸ªå¾®æ‰¹ä½œä¸šï¼Œç±»ä¼¼äºæ‰¹å¤„ç†çš„æ–¹å¼è¿›è¡Œå¤„ç†ã€‚
   - æŒç»­å¤„ç†ï¼ˆcontinuous processingï¼‰ï¼šå¯¹ä¸é—´æ–­çš„æ•°æ®æµè¿›è¡Œå®æ—¶å¤„ç†ï¼Œæ²¡æœ‰æ˜ç¡®çš„æ‰¹æ¬¡è¾¹ç•Œï¼Œæ•°æ®åˆ°è¾¾åç«‹å³è¿›è¡Œå¤„ç†å’Œè¾“å‡ºã€‚
2. **å»¶è¿Ÿå’Œå®æ—¶æ€§**ï¼š
   - å¾®æ‰¹å¤„ç†é€šå¸¸ä¼šå¯¼è‡´ä¸€å®šçš„å»¶è¿Ÿï¼Œå› ä¸ºæ•°æ®éœ€è¦ç­‰å¾…ä¸‹ä¸€ä¸ªæ‰¹æ¬¡çš„å¤„ç†æ‰èƒ½è¾“å‡ºç»“æœï¼Œå› æ­¤å¾®æ‰¹å¤„ç†ä¸€èˆ¬æ— æ³•åšåˆ°å®Œå…¨çš„å®æ—¶æ€§ã€‚
   - æŒç»­å¤„ç†å…·æœ‰æ›´å¥½çš„å®æ—¶æ€§ï¼Œå› ä¸ºæ•°æ®åˆ°è¾¾åç«‹å³è¿›è¡Œå¤„ç†ï¼Œå¯ä»¥æ›´å¿«åœ°è¾“å‡ºç»“æœã€‚
3. **å®¹é”™å’ŒçŠ¶æ€ç®¡ç†**ï¼š
   - å¾®æ‰¹å¤„ç†é€šå¸¸é€šè¿‡æ£€æŸ¥ç‚¹æœºåˆ¶æ¥å®ç°å®¹é”™å’ŒçŠ¶æ€ç®¡ç†ï¼Œæ¯ä¸ªå¾®æ‰¹ä½œä¸šä¹‹é—´ä¼šä¿å­˜å¤„ç†çŠ¶æ€ï¼Œä»¥ä¾¿æ•…éšœæ¢å¤å’Œé‡æ–°æ‰§è¡Œã€‚
   - æŒç»­å¤„ç†ä¹Ÿéœ€è¦è€ƒè™‘å®¹é”™å’ŒçŠ¶æ€ç®¡ç†ï¼Œä½†é€šå¸¸éœ€è¦ä½¿ç”¨æ›´å¤æ‚çš„æœºåˆ¶æ¥å®ç°å®æ—¶çš„çŠ¶æ€ç®¡ç†å’Œæ•…éšœæ¢å¤ã€‚
4. **èµ„æºåˆ©ç”¨**ï¼š
   - å¾®æ‰¹å¤„ç†å¯ä»¥æ›´å¥½åœ°åˆ©ç”¨æ‰¹å¤„ç†ç³»ç»Ÿçš„èµ„æºï¼Œå› ä¸ºå¯ä»¥å¯¹æ•°æ®è¿›è¡Œåˆ†æ‰¹å¤„ç†ï¼Œé€‚ç”¨äºä¸€äº›éœ€è¦å¤§æ‰¹é‡æ•°æ®ä¸€èµ·å¤„ç†çš„åœºæ™¯ã€‚
   - æŒç»­å¤„ç†éœ€è¦æ›´å¤šçš„å®æ—¶èµ„æºå’Œæ›´é«˜çš„å®æ—¶æ€§èƒ½ï¼Œé€‚ç”¨äºå¯¹æ•°æ®è¦æ±‚å®æ—¶æ€§è¾ƒé«˜çš„åœºæ™¯ã€‚

## 1.3 Structured Streamingå’ŒSpark SQLã€Spark Streamingå…³ç³»

- Structured Streamingå¤„ç†çš„æ•°æ®è·ŸSpark Streamingä¸€æ ·ï¼Œä¹Ÿæ˜¯æºæºä¸æ–­çš„æ•°æ®æµï¼ŒåŒºåˆ«åœ¨äºï¼Œ<font color=gree>Spark Streaming</font>é‡‡ç”¨çš„æ•°æ®æŠ½è±¡æ˜¯<font color=gree>DStream</font>ï¼ˆæœ¬è´¨ä¸Šå°±æ˜¯ä¸€ç³»åˆ—RDDï¼‰ï¼Œè€Œ<font color=green>Structured Streaming</font>é‡‡ç”¨çš„æ•°æ®æŠ½è±¡æ˜¯<font color=green>DataFrame</font>ã€‚
- Structured Streamingå¯ä»¥ä½¿ç”¨Spark SQLçš„DataFrame/Datasetæ¥å¤„ç†æ•°æ®æµã€‚è™½ç„¶Spark SQLä¹Ÿæ˜¯é‡‡ç”¨DataFrameä½œä¸ºæ•°æ®æŠ½è±¡ï¼Œä½†æ˜¯ï¼ŒSpark SQLåªèƒ½å¤„ç†é™æ€çš„æ•°æ®ï¼Œè€ŒStructured Streamingå¯ä»¥å¤„ç†ç»“æ„åŒ–çš„æ•°æ®æµã€‚è¿™æ ·ï¼ŒStructured Streamingå°±å°†Spark SQLå’ŒSpark StreamingäºŒè€…çš„ç‰¹æ€§ç»“åˆäº†èµ·æ¥ã€‚
- Structured Streamingå¯ä»¥å¯¹DataFrame/Datasetåº”ç”¨å„ç§æ“ä½œï¼ŒåŒ…æ‹¬selectã€whereã€groupByã€mapã€filterã€flatMapç­‰ã€‚
- Spark Streamingåªèƒ½å®ç°ç§’çº§çš„å®æ—¶å“åº”ï¼Œè€ŒStructured Streamingç”±äºé‡‡ç”¨äº†å…¨æ–°çš„è®¾è®¡æ–¹å¼ï¼Œé‡‡ç”¨å¾®æ‰¹å¤„ç†æ¨¡å‹æ—¶å¯ä»¥å®ç°100æ¯«ç§’çº§åˆ«çš„å®æ—¶å“åº”ï¼Œé‡‡ç”¨æŒç»­å¤„ç†æ¨¡å‹æ—¶å¯ä»¥æ”¯æŒæ¯«ç§’çº§çš„å®æ—¶å“åº”ã€‚

# äºŒã€ç¼–å†™Structured Streamingç¨‹åºçš„åŸºæœ¬æ­¥éª¤

ç¼–å†™Structured Streamingç¨‹åºçš„åŸºæœ¬æ­¥éª¤åŒ…æ‹¬ï¼š

- å¯¼å…¥pysparkæ¨¡å—
- åˆ›å»ºSparkSessionå¯¹è±¡
- åˆ›å»ºè¾“å…¥æ•°æ®æº
- å®šä¹‰æµè®¡ç®—è¿‡ç¨‹
- å¯åŠ¨æµè®¡ç®—å¹¶è¾“å‡ºç»“æœ

å®ä¾‹ä»»åŠ¡ï¼šä¸€ä¸ªåŒ…å«å¾ˆå¤šè¡Œè‹±æ–‡è¯­å¥çš„æ•°æ®æµæºæºä¸æ–­åˆ°è¾¾ï¼ŒStructured Streamingç¨‹åºå¯¹æ¯è¡Œè‹±æ–‡è¯­å¥è¿›è¡Œæ‹†åˆ†ï¼Œå¹¶ç»Ÿè®¡æ¯ä¸ªå•è¯å‡ºç°çš„é¢‘ç‡

åœ¨/home/hadoop/sparksj/mycode/structuredç›®å½•ä¸‹åˆ›å»ºStructuredNetworkWordCount.pyæ–‡ä»¶ï¼š

```python
# å¯¼å…¥å¿…è¦çš„ SparkSession å’Œå‡½æ•°åº“
from pyspark.sql import SparkSession
from pyspark.sql.functions import split
from pyspark.sql.functions import explode

# ç¨‹åºçš„å…¥å£ç‚¹ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨ä¸»ç¨‹åºä¸­æ‰§è¡Œ
if __name__ == "__main__":
    # åˆ›å»º SparkSession å¯¹è±¡ï¼Œè®¾ç½®åº”ç”¨ç¨‹åºåå­—ä¸º "StructuredNetworkWordCount"
    spark = SparkSession \
        .builder \
        .appName("StructuredNetworkWordCount") \
        .getOrCreate()
    
    # è®¾ç½® Spark æ—¥å¿—çº§åˆ«ä¸º WARNï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
    spark.sparkContext.setLogLevel('WARN')
    
    # ä»æŒ‡å®šçš„ä¸»æœºï¼ˆlocalhostï¼‰å’Œç«¯å£ï¼ˆ9999ï¼‰è¯»å–æ•°æ®æµï¼Œä½¿ç”¨ "socket" æ ¼å¼
    lines = spark \
        .readStream \
        .format("socket") \
        .option("host", "localhost") \
        .option("port", 9999) \
        .load()
    
    # å°†æ¯è¡Œæ•°æ®æŒ‰ç©ºæ ¼åˆ†å‰²æˆå•è¯ï¼Œå¹¶ä½¿ç”¨ explode å‡½æ•°å°†å•è¯å±•å¼€æˆè¡Œ
    words = lines.select(explode(split(lines.value, " ")).alias("word"))
    
    # å¯¹å•è¯è¿›è¡Œåˆ†ç»„è®¡æ•°
    wordCounts = words.groupBy("word").count()
    
    # å°†ç»“æœå†™å…¥åˆ°æ§åˆ¶å°ï¼Œè¾“å‡ºæ¨¡å¼ä¸º "complete"ï¼Œæ¯8ç§’è§¦å‘ä¸€æ¬¡æµå¤„ç†
    query = wordCounts \
        .writeStream \
        .outputMode("complete") \
        .format("console") \
        .trigger(processingTime="8 seconds") \
        .start()
    
    # ç­‰å¾…æµæŸ¥è¯¢ç»ˆæ­¢
    query.awaitTermination()
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89f209fea4fd96dcb6c140f0a4e99f30c0.png)

åœ¨æ‰§è¡ŒStructuredNetworkWordCount.pyä¹‹å‰ï¼Œéœ€è¦å¯åŠ¨HDFSï¼š

```bash
start-dfs.sh
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89328eb978cf0a606f27b51b5009a92608.png)

æ–°å»ºä¸€ä¸ªç»ˆç«¯ï¼ˆè®°ä½œâ€œæ•°æ®æºç»ˆç«¯â€ï¼‰ï¼Œè¾“å…¥å¦‚ä¸‹å‘½ä»¤ï¼š

```bash
nc -lk 9999
```

å†æ–°å»ºä¸€ä¸ªç»ˆç«¯ï¼ˆè®°ä½œâ€œæµè®¡ç®—ç»ˆç«¯â€ï¼‰ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š

```bash
cd /home/hadoop/sparksj/mycode/structured
spark-submit StructuredNetworkWordCount.py
```

æ‰§è¡Œç¨‹åºåï¼Œåœ¨â€œæ•°æ®æºç»ˆç«¯â€å†…ç”¨é”®ç›˜ä¸æ–­æ•²å…¥ä¸€è¡Œè¡Œè‹±æ–‡è¯­å¥ï¼Œncç¨‹åºä¼šæŠŠè¿™äº›æ•°æ®å‘é€ç»™StructuredNetworkWordCount.pyç¨‹åºè¿›è¡Œå¤„ç†ï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89ccb4270dbbd19fd3ffd4ba0bce3e536f.png)

è¾“å‡ºç»“æœå†…çš„Batchåé¢çš„æ•°å­—ï¼Œè¯´æ˜è¿™æ˜¯ç¬¬å‡ ä¸ªå¾®æ‰¹å¤„ç†ï¼Œç³»ç»Ÿæ¯éš”8ç§’ä¼šå¯åŠ¨ä¸€æ¬¡å¾®æ‰¹å¤„ç†å¹¶è¾“å‡ºæ•°æ®ã€‚å¦‚æœè¦åœæ­¢ç¨‹åºçš„è¿è¡Œï¼Œåˆ™å¯ä»¥åœ¨ç»ˆç«¯å†…é”®å…¥â€œ<font color=red>**Ctrl+C**</font>â€æ¥åœæ­¢ã€‚

# ä¸‰ã€è¾“å…¥æº

## 3.1 Fileæº

Fileæºï¼ˆæˆ–ç§°ä¸ºâ€œæ–‡ä»¶æºâ€ï¼‰ä»¥æ–‡ä»¶æµçš„å½¢å¼è¯»å–æŸä¸ªç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œæ”¯æŒçš„æ–‡ä»¶æ ¼å¼ä¸ºcsvã€jsonã€orcã€parquetã€textç­‰ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ–‡ä»¶æ”¾ç½®åˆ°ç»™å®šç›®å½•çš„æ“ä½œåº”å½“æ˜¯åŸå­æ€§çš„ï¼Œå³ä¸èƒ½é•¿æ—¶é—´åœ¨ç»™å®šç›®å½•å†…æ‰“å¼€æ–‡ä»¶å†™å…¥å†…å®¹ï¼Œè€Œæ˜¯åº”å½“é‡‡å–å¤§éƒ¨åˆ†æ“ä½œç³»ç»Ÿéƒ½æ”¯æŒçš„ã€é€šè¿‡å†™å…¥åˆ°ä¸´æ—¶æ–‡ä»¶åç§»åŠ¨æ–‡ä»¶åˆ°ç»™å®šç›®å½•çš„æ–¹å¼æ¥å®Œæˆã€‚

File æºçš„[é€‰é¡¹](https://spark.apache.org/docs/3.2.0/sql-data-sources.html)ï¼ˆoptionï¼‰ä¸»è¦åŒ…æ‹¬å¦‚ä¸‹å‡ ä¸ªï¼š

- pathï¼šè¾“å…¥è·¯å¾„çš„ç›®å½•ï¼Œæ‰€æœ‰æ–‡ä»¶æ ¼å¼é€šç”¨ã€‚path æ”¯æŒglob é€šé…ç¬¦è·¯å¾„ï¼Œä½†æ˜¯ç›®å½•æˆ–globé€šé…ç¬¦è·¯å¾„çš„æ ¼å¼ä¸æ”¯æŒä»¥å¤šä¸ªé€—å·åˆ†éš”çš„å½¢å¼ã€‚
- maxFilesPerTriggerï¼šæ¯ä¸ªè§¦å‘å™¨ä¸­è¦å¤„ç†çš„æœ€å¤§æ–°æ–‡ä»¶æ•°ï¼ˆé»˜è®¤æ— æœ€å¤§å€¼ï¼‰ã€‚
- latestFirstï¼šæ˜¯å¦ä¼˜å…ˆå¤„ç†æœ€æ–°çš„æ–‡ä»¶ï¼Œå½“æœ‰å¤§é‡æ–‡ä»¶ç§¯å‹æ—¶ï¼Œè®¾ç½®ä¸ºTrueå¯ä»¥ä¼˜å…ˆå¤„ç†æ–°æ–‡ä»¶ï¼Œé»˜è®¤ä¸ºFalseã€‚
- fileNameOnlyï¼šæ˜¯å¦ä»…æ ¹æ®æ–‡ä»¶åè€Œä¸æ˜¯å®Œæ•´è·¯å¾„æ¥æ£€æŸ¥æ–°æ–‡ä»¶ï¼Œé»˜è®¤ä¸ºFalseã€‚å¦‚æœè®¾ç½®ä¸ºTrueï¼Œåˆ™ä»¥ä¸‹æ–‡ä»¶å°†è¢«è§†ä¸ºç›¸åŒçš„æ–‡ä»¶ï¼Œå› ä¸ºå®ƒä»¬çš„æ–‡ä»¶åâ€œdataset.txtâ€ç›¸åŒï¼š

> "file:///dataset.txt"
>
> "s3://a/dataset.txt"
>
> "s3n://a/b/dataset.txt"
>
> "s3a://a/b/c/dataset.txt"

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%897bb3ff0c2679cbed376808f40db676d8.png)

ç‰¹å®šçš„æ–‡ä»¶æ ¼å¼ä¹Ÿæœ‰ä¸€äº›å…¶ä»–ç‰¹å®šçš„é€‰é¡¹ï¼Œå…·ä½“å¯ä»¥å‚é˜…[Sparkæ‰‹å†Œ](https://spark.apache.org/docs/3.2.0/index.html)å†…[DataStreamReader](https://spark.apache.org/docs/3.2.0/api/python/reference/api/pyspark.sql.streaming.DataStreamReader.html#pyspark.sql.streaming.DataStreamReader)ä¸­çš„ç›¸å…³è¯´æ˜ï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%890c5e61994b0735b82110427481590cc2.png)

ä»¥.csvæ–‡ä»¶æºä¸ºä¾‹ï¼Œä»¥ä¸‹ä¸ºç¤ºä¾‹ä»£ç ï¼š

```python
csvDF = spark \
    .readStream \
    .format("csv") \
    .option("seq",";") \
    .load("SOME_DIR")
```

å…¶ä¸­ï¼Œseqé€‰é¡¹æŒ‡å®šäº†.csvçš„é—´éš”ç¬¦å·ã€‚

**å®ä¾‹ï¼š**

ä»¥ä¸€ä¸ªJSONæ ¼å¼æ–‡ä»¶çš„å¤„ç†æ¥æ¼”ç¤ºFileæºçš„ä½¿ç”¨æ–¹æ³•ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹ä¸¤ä¸ªæ­¥éª¤ï¼š

- åˆ›å»ºç¨‹åºç”ŸæˆJSONæ ¼å¼çš„Fileæºæµ‹è¯•æ•°æ®
- åˆ›å»ºç¨‹åºå¯¹æ•°æ®è¿›è¡Œç»Ÿè®¡

### ï¼ˆ1ï¼‰åˆ›å»ºç¨‹åºç”ŸæˆJSONæ ¼å¼çš„Fileæºæµ‹è¯•æ•°æ®

ç”Ÿæˆæ¨¡æ‹Ÿçš„ç”µå•†è´­ä¹°è¡Œä¸ºæ•°æ®ï¼Œå¹¶å°†æ•°æ®ä¿å­˜ä¸º JSON æ–‡ä»¶ã€‚æ¨¡æ‹Ÿäº†ç”¨æˆ·çš„ç™»å½•ã€ç™»å‡ºå’Œè´­ä¹°è¡Œä¸ºï¼ŒåŒ…æ‹¬äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´æˆ³ã€åŠ¨ä½œç±»å‹å’Œåœ°åŒºç­‰ä¿¡æ¯

åœ¨/home/hadoop/sparksj/mycode/structuredç›®å½•ä¸‹åˆ›å»ºa.pyæ–‡ä»¶ï¼š

```python
import os                  # å¯¼å…¥ os æ¨¡å—ï¼Œç”¨äºå¤„ç†æ–‡ä»¶å’Œç›®å½•è·¯å¾„
import shutil              # å¯¼å…¥ shutil æ¨¡å—ï¼Œç”¨äºæ–‡ä»¶æ“ä½œï¼Œæ¯”å¦‚ç§»åŠ¨æ–‡ä»¶
import random              # å¯¼å…¥ random æ¨¡å—ï¼Œç”¨äºç”Ÿæˆéšæœºæ•°
import time                # å¯¼å…¥ time æ¨¡å—ï¼Œç”¨äºè·å–æ—¶é—´æˆ³

# å®šä¹‰æµ‹è¯•æ•°æ®å­˜å‚¨çš„ä¸´æ—¶ç›®å½•å’Œæœ€ç»ˆç›®å½•
TEST_DATA_TEMP_DIR = '/tmp/'    # ä¸´æ—¶ç›®å½•ï¼Œç”¨äºç”Ÿæˆæ–‡ä»¶
TEST_DATA_DIR = '/tmp/testdata/'  # æœ€ç»ˆç›®å½•ï¼Œå­˜å‚¨ç”Ÿæˆçš„æ–‡ä»¶

# å®šä¹‰å¯èƒ½çš„è¡Œä¸ºå’Œåœ°åŒº
ACTION_DEF = ['login', 'logout', 'purchase']  # å¯èƒ½çš„è¡Œä¸º
DISTRICT_DEF = ['fujian', 'beijing', 'shanghai', 'guangzhou']  # å¯èƒ½çš„åœ°åŒº

# JSON è¡Œçš„æ¨¡æ¿ï¼ŒåŒ…å«æ—¶é—´ã€è¡Œä¸ºå’Œåœ°åŒº
JSON_LINE_PATTERN = '{"eventTime": "{}", "action": "{}", "district": "{}"}\n'

# è®¾ç½®æµ‹è¯•ç¯å¢ƒï¼Œæ¸…ç©ºæœ€ç»ˆç›®å½•
def test_setUp():
    if os.path.exists(TEST_DATA_DIR):       # æ£€æŸ¥æœ€ç»ˆç›®å½•æ˜¯å¦å­˜åœ¨
        shutil.rmtree(TEST_DATA_DIR, ignore_errors=True)  # å¦‚æœå­˜åœ¨ï¼Œé€’å½’åˆ é™¤ç›®å½•åŠå…¶å†…å®¹
    os.mkdir(TEST_DATA_DIR)                  # åˆ›å»ºæœ€ç»ˆç›®å½•

# æ¸…ç†æµ‹è¯•ç¯å¢ƒï¼Œåˆ é™¤æœ€ç»ˆç›®å½•åŠå…¶å†…å®¹
def test_tearDown():
    if os.path.exists(TEST_DATA_DIR):       # æ£€æŸ¥æœ€ç»ˆç›®å½•æ˜¯å¦å­˜åœ¨
        shutil.rmtree(TEST_DATA_DIR, ignore_errors=True)  # å¦‚æœå­˜åœ¨ï¼Œé€’å½’åˆ é™¤ç›®å½•åŠå…¶å†…å®¹

# å†™å…¥æ–‡ä»¶å¹¶ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•
def write_and_move(filename, data):
    with open(TEST_DATA_TEMP_DIR + filename,"wt", encoding="utf-8") as f:  # æ‰“å¼€ä¸´æ—¶ç›®å½•ä¸‹çš„æ–‡ä»¶å¹¶å†™å…¥æ•°æ®
        f.write(data)                                                     # å†™å…¥æ•°æ®åˆ°æ–‡ä»¶

    shutil.move(TEST_DATA_TEMP_DIR + filename, TEST_DATA_DIR + filename)   # å°†æ–‡ä»¶ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•

# ä¸»ç¨‹åº
if __name__ == "__main__":    # ç¨‹åºçš„å…¥å£ï¼Œå¦‚æœä½œä¸ºè„šæœ¬ç›´æ¥æ‰§è¡Œï¼Œåˆ™ä¼šæ‰§è¡Œä¸‹é¢çš„ä»£ç 
    test_setUp()               # è®¾ç½®æµ‹è¯•ç¯å¢ƒï¼Œæ¸…ç©ºæœ€ç»ˆç›®å½•

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼Œå¾ªç¯ç”Ÿæˆ100ä¸ªæ–‡ä»¶
    for i in range(100):
        filename = 'e-mall-{}.json'.format(i)    # ç”Ÿæˆæ–‡ä»¶åï¼Œæ ¼å¼ä¸º e-mall-i.json

        content = ''                              # åˆå§‹åŒ–å†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²
        rndcount = list(range(10))                # ç”Ÿæˆä¸€ä¸ªåŒ…å«0åˆ°9çš„åˆ—è¡¨
        random.shuffle(rndcount)                  # æ‰“ä¹±åˆ—è¡¨é¡ºåºï¼Œéšæœºç”Ÿæˆè¡Œæ•°
        for _ in rndcount:                        # éå†æ¯ä¸€ä¸ªéšæœºæ•°
            content += JSON_LINE_PATTERN.format(  # æ ¹æ®æ¨¡æ¿ç”Ÿæˆä¸€è¡Œ JSON æ•°æ®
                str(int(time.time())),            # æ—¶é—´æˆ³ï¼Œå½“å‰æ—¶é—´çš„ç§’æ•°ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                random.choice(ACTION_DEF),        # éšæœºé€‰æ‹©è¡Œä¸º
                random.choice(DISTRICT_DEF))      # éšæœºé€‰æ‹©åœ°åŒº
        write_and_move(filename, content)         # è°ƒç”¨å‡½æ•°å†™å…¥æ•°æ®åˆ°æ–‡ä»¶å¹¶ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•

        time.sleep(1)                             # ä¼‘çœ 1ç§’ï¼Œæ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆé—´éš”

    test_tearDown()                              # æ¸…ç†æµ‹è¯•ç¯å¢ƒï¼Œåˆ é™¤æœ€ç»ˆç›®å½•åŠå…¶å†…å®¹
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89c6bac2f6c8c44b25c9646487963c84b6.jpeg)

è¿™æ®µç¨‹åºé¦–å…ˆå»ºç«‹æµ‹è¯•ç¯å¢ƒï¼Œæ¸…ç©ºæµ‹è¯•æ•°æ®æ‰€åœ¨çš„ç›®å½•ï¼Œæ¥ç€ä½¿ç”¨forå¾ªç¯ä¸€åƒæ¬¡æ¥ç”Ÿæˆä¸€åƒä¸ªæ–‡ä»¶ï¼Œæ–‡ä»¶åä¸ºâ€œe-mall-æ•°å­—.jsonâ€ï¼Œ æ–‡ä»¶å†…å®¹æ˜¯ä¸è¶…è¿‡100è¡Œçš„éšæœºJSONè¡Œï¼Œè¡Œçš„æ ¼å¼æ˜¯ç±»ä¼¼å¦‚ä¸‹ï¼š

> {"eventTime": 1546939167, "action": "logout", "district": "fujian"}\n

å…¶ä¸­ï¼Œæ—¶é—´ã€æ“ä½œå’Œçœä¸åœ°åŒºå‡éšæœºç”Ÿæˆã€‚æµ‹è¯•æ•°æ®æ˜¯æ¨¡æ‹Ÿç”µå­å•†åŸè®°å½•ç”¨æˆ·çš„è¡Œä¸ºï¼Œå¯èƒ½æ˜¯ç™»å½•ã€é€€å‡ºæˆ–è€…è´­ä¹°ï¼Œå¹¶è®°å½•äº†ç”¨æˆ·æ‰€åœ¨çš„çœä¸åœ°åŒºã€‚ä¸ºäº†è®©ç¨‹åºè¿è¡Œä¸€æ®µæ—¶é—´ï¼Œæ¯ç”Ÿæˆä¸€ä¸ªæ–‡ä»¶åä¼‘çœ 1ç§’ã€‚åœ¨ä¸´æ—¶ç›®å½•å†…ç”Ÿæˆçš„æ–‡ä»¶ï¼Œé€šè¿‡ç§»åŠ¨ï¼ˆmoveï¼‰çš„<font color=red>åŸå­æ“ä½œ</font>ç§»åŠ¨åˆ°æµ‹è¯•ç›®å½•ã€‚

### ï¼ˆ2ï¼‰åˆ›å»ºç¨‹åºå¯¹æ•°æ®è¿›è¡Œç»Ÿè®¡

åŒæ ·ï¼Œåœ¨/home/hadoop/sparksj/mycode/structuredç›®å½•ä¸‹åˆ›å»ºb.pyæ–‡ä»¶ï¼š

```python
import os                              # å¯¼å…¥ os æ¨¡å—ï¼Œç”¨äºå¤„ç†æ–‡ä»¶å’Œç›®å½•è·¯å¾„
import shutil                          # å¯¼å…¥ shutil æ¨¡å—ï¼Œç”¨äºæ–‡ä»¶æ“ä½œï¼Œæ¯”å¦‚ç§»åŠ¨æ–‡ä»¶
from pprint import pprint             # å¯¼å…¥ pprint æ¨¡å—ï¼Œç”¨äºæ¼‚äº®åœ°æ‰“å°æ•°æ®ç»“æ„

from pyspark.sql import SparkSession  # ä» PySpark ä¸­å¯¼å…¥ SparkSessionï¼Œç”¨äºåˆ›å»º Spark åº”ç”¨ç¨‹åº
from pyspark.sql.functions import window, asc  # ä» PySpark ä¸­å¯¼å…¥çª—å£å‡½æ•°å’Œå‡åºæ’åºå‡½æ•°
from pyspark.sql.types import StructType, StructField, TimestampType, StringType  # ä» PySpark ä¸­å¯¼å…¥ç»“æ„ç±»å‹å’Œæ—¶é—´æˆ³ç±»å‹ã€å­—ç¬¦ä¸²ç±»å‹

TEST_DATA_DIR_SPARK = 'file:///tmp/testdata/'  # æµ‹è¯•æ•°æ®å­˜å‚¨çš„ç›®å½•ï¼Œä½¿ç”¨ file:/// å¼€å¤´è¡¨ç¤ºæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè·¯å¾„

if __name__ == "__main__":  # ç¨‹åºå…¥å£ï¼Œå¦‚æœä½œä¸ºè„šæœ¬ç›´æ¥æ‰§è¡Œï¼Œåˆ™æ‰§è¡Œä¸‹é¢çš„ä»£ç 

    # å®šä¹‰æ¨¡æ‹Ÿæ•°æ®çš„ç»“æ„
    schema = StructType([
        StructField("eventTime", TimestampType(), True),  # å®šä¹‰äº‹ä»¶æ—¶é—´å­—æ®µï¼Œç±»å‹ä¸ºæ—¶é—´æˆ³
        StructField("action", StringType(), True),        # å®šä¹‰è¡Œä¸ºå­—æ®µï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²
        StructField("district", StringType(), True)])     # å®šä¹‰åœ°åŒºå­—æ®µï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²

    # åˆ›å»º SparkSessionï¼Œå¦‚æœå·²å­˜åœ¨åˆ™è·å–ï¼Œå¦åˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„
    spark = SparkSession \
        .builder \
        .appName("StructuredEMallPurchaseCount") \  # è®¾ç½®åº”ç”¨ç¨‹åºåç§°
        .getOrCreate()

    spark.sparkContext.setLogLevel('WARN')  # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º WARNï¼Œä»¥å‡å°‘ä¸å¿…è¦çš„æ—¥å¿—è¾“å‡º

    # ä»æ–‡ä»¶æµä¸­è¯»å– JSON æ•°æ®ï¼Œåº”ç”¨æŒ‡å®šçš„æ¨¡å¼
    lines = spark \
        .readStream \
        .format("json") \
        .schema(schema) \
        .option("maxFilesPerTrigger", 100) \  # æ¯æ¬¡è§¦å‘å¤„ç†çš„æœ€å¤§æ–‡ä»¶æ•°ï¼Œä»¥æ§åˆ¶å¤„ç†é€Ÿåº¦
        .load(TEST_DATA_DIR_SPARK)

    windowDuration = '1 minutes'  # å®šä¹‰æ—¶é—´çª—å£çš„æŒç»­æ—¶é—´

    # å¯¹è´­ä¹°è¡Œä¸ºè¿›è¡Œç­›é€‰ã€æŒ‰åœ°åŒºå’Œæ—¶é—´çª—å£è¿›è¡Œåˆ†ç»„ç»Ÿè®¡è´­ä¹°æ¬¡æ•°ï¼Œå¹¶æŒ‰æ—¶é—´çª—å£æ’åº
    windowedCounts = lines \
        .filter("action = 'purchase'") \
        .groupBy('district', window('eventTime', windowDuration)) \
        .count() \
        .sort(asc('window'))

    # å°†ç»“æœå†™å…¥æ§åˆ¶å°
    query = windowedCounts \
        .writeStream \
        .outputMode("complete") \
        .format("console") \
        .option('truncate', 'false') \  # æ§åˆ¶å°è¾“å‡ºä¸æˆªæ–­
        .trigger(processingTime="10 seconds") \  # è§¦å‘å¤„ç†çš„æ—¶é—´é—´éš”
        .start()

    query.awaitTermination()  # ç­‰å¾…æŸ¥è¯¢ç»ˆæ­¢
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%898a08cc945490124bd7c359cd2998cbed.jpeg)

è¯¥ç¨‹åºçš„ç›®çš„æ˜¯è¿‡æ»¤ç”¨æˆ·åœ¨ç”µå­å•†åŸé‡Œçš„è´­ä¹°è®°å½•ï¼Œå¹¶æ ¹æ®çœä¸åœ°åŒºä»¥1åˆ†é’Ÿçš„æ—¶é—´çª—å£ç»Ÿè®¡å„ä¸ªçœä¸åœ°åŒºçš„è´­ä¹°é‡ï¼Œå¹¶æŒ‰æ—¶é—´æ’åºåè¾“å‡ºã€‚

### ï¼ˆ3ï¼‰æµ‹è¯•è¿è¡Œç¨‹åº

ç¨‹åºè¿è¡Œè¿‡ç¨‹éœ€è¦è®¿é—®HDFSï¼Œå› æ­¤ï¼Œéœ€è¦å¯åŠ¨HDFSï¼š

```bash
start-dfs.sh
```

æ–°å»ºä¸€ä¸ªç»ˆç«¯ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼š

```bash
cd /home/hadoop/sparksj/mycode/structured
python3 a.py
```

å†æ¬¡æ–°å»ºä¸€ä¸ªç»ˆç«¯ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤è¿è¡Œæ•°æ®ç»Ÿè®¡ç¨‹åºï¼š

```bash
cd /home/hadoop/sparksj/mycode/structured
spark-submit b.py
```

è¿è¡Œç¨‹åºä»¥åï¼Œå¯ä»¥çœ‹åˆ°ç±»ä¼¼å¦‚ä¸‹çš„è¾“å‡ºç»“æœï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%892c9714f22ccd8034e6897635daebe84b.png)

### ï¼ˆ4ï¼‰å¤„ç†è­¦å‘Š

å¦‚æœè¿è¡Œè¿‡ç¨‹ä¸­å‡ºç°è­¦å‘Šå¯å¿½ç•¥ï¼Œ<font color=red>ä¸å½±å“æ­£å¸¸è¿è¡Œ</font>ï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%892c305868ae60a1c189523f69e570cca6.png)

------

è¿è¡Œè¿‡ç¨‹ä¸­å‡ºç°å¦‚ä¸‹è­¦å‘Šï¼Œå½“ç„¶ä¹Ÿ<font color=red>ä¸å½±å“è¿è¡Œ</font>ï¼Œä¹Ÿå¯ä»¥è¿›è¡Œè§£å†³ï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89941db61980c7ef6d0d058527b189d927.png)

æ„æ€å°±æ˜¯å¤„ç†æ—¶é—´è§¦å‘å™¨çš„æ‰¹å¤„ç†å·²ç»å¼€å§‹æ»åã€‚å…·ä½“æ¥è¯´ï¼Œå½“å‰æ‰¹å¤„ç†èŠ±è´¹çš„æ—¶é—´è¶…è¿‡äº†è§¦å‘å™¨è®¾å®šçš„æ—¶é—´é—´éš”

ä¸Šè¿°ä»£ç ä¸­è§¦å‘å™¨çš„é—´éš”è¢«è®¾ç½®ä¸º 10000 æ¯«ç§’ï¼ˆä¹Ÿå°±æ˜¯10ç§’ï¼‰ï¼Œä½†æ˜¯å½“å‰æ‰¹å¤„ç†èŠ±è´¹äº†16341æ¯«ç§’ï¼Œè¿œè¿œè¶…è¿‡äº†è®¾å®šçš„æ—¶é—´é—´éš”

å¯èƒ½ä¼šå¯¼è‡´ï¼š

1. **å¤„ç†å»¶è¿Ÿ**: å½“æ‰¹å¤„ç†èŠ±è´¹çš„æ—¶é—´è¶…è¿‡è§¦å‘å™¨è®¾å®šçš„æ—¶é—´é—´éš”æ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´å¤„ç†å»¶è¿Ÿï¼Œå› ä¸ºä¸‹ä¸€ä¸ªæ‰¹å¤„ç†å¯èƒ½æ— æ³•æŒ‰æ—¶å¯åŠ¨ã€‚
2. **èµ„æºåˆ©ç”¨ä¸ä½³**: å¦‚æœæ‰¹å¤„ç†æŒç»­èŠ±è´¹è¾ƒé•¿æ—¶é—´ï¼Œå¯èƒ½ä¼šå¯¼è‡´èµ„æºï¼ˆå¦‚CPUã€å†…å­˜ç­‰ï¼‰çš„æµªè´¹ï¼Œå› ä¸ºèµ„æºè¢«ç”¨äºç­‰å¾…è€Œä¸æ˜¯å®é™…çš„å¤„ç†ä»»åŠ¡ã€‚

ä¸Šè¿°è­¦å‘Šå¯é€šè¿‡ä¿®æ”¹b.pyä»£ç ä¸­'<font color=gree>processingTime</font>'çš„å€¼ï¼Œå°†å®ƒæ”¹æˆå¤§äºä¸Šå›¾ä¸­çš„16341mså³å¯ï¼ˆ1ç§’=1000æ¯«ç§’ï¼‰

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89e2ed9f9145dcca3f2b473db305d3ec0f.png)

------

å½“ç„¶ï¼Œè‹¥è¯»è€…åŒçƒ¦äºè¿™äº›è­¦å‘Šï¼Œä¹Ÿå¯ä¸é€‰æ‹©<font color=red>è®¾ç½®</font> Apache Spark çš„<font color=red>æ—¥å¿—çº§åˆ«ä¸º ERROR</font>ï¼Œåªè®°å½• ERROR çº§åˆ«åŠä»¥ä¸Šçš„æ—¥å¿—ä¿¡æ¯

å°†b.pyä»£ç ä¸­çš„spark.sparkContext.setLogLevel('WARN')æ”¹ä¸ºspark.sparkContext.setLogLevel('ERROR')å³å¯ï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89fa201be6bc94a254cb669cd315240e41.png)

ä¿å­˜å¹¶å†æ¬¡è¿è¡Œå¯å¾—åˆ°å¹²å‡€æ•´æ´çš„ç»“æœï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%8909c24413ed490d21425e5b536b2f9718.png)

### ï¼ˆ5ï¼‰æ€»ç»“åˆ†æ

a.pyæ˜¯ä¸€ä¸ª Python è„šæœ¬ï¼Œç”¨äºç”Ÿæˆæ¨¡æ‹Ÿçš„ç”µå•†è´­ä¹°è¡Œä¸ºæ•°æ®ï¼Œå¹¶å°†æ•°æ®ä¿å­˜ä¸º JSON æ–‡ä»¶ã€‚å®ƒæ¨¡æ‹Ÿäº†ç”¨æˆ·çš„ç™»å½•ã€ç™»å‡ºå’Œè´­ä¹°è¡Œä¸ºï¼ŒåŒ…æ‹¬äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´æˆ³ã€åŠ¨ä½œç±»å‹å’Œåœ°åŒºç­‰ä¿¡æ¯ã€‚

b.pyæ˜¯ä¸€ä¸ª PySpark Structured Streaming åº”ç”¨ç¨‹åºï¼Œç”¨äºå®æ—¶å¤„ç†æ¨¡æ‹Ÿçš„ç”µå•†è´­ä¹°è¡Œä¸ºæ•°æ®ã€‚å®ƒä»æŒ‡å®šçš„ç›®å½•ï¼ˆå³a.pyç”Ÿæˆçš„ JSON æ–‡ä»¶ç›®å½•ï¼‰è¯»å–æ•°æ®ï¼Œå¹¶è¿›è¡Œå®æ—¶ç»Ÿè®¡ï¼Œè®¡ç®—æ¯ä¸ªåœ°åŒºåœ¨ä¸€åˆ†é’Ÿå†…çš„è´­ä¹°æ¬¡æ•°ï¼Œå¹¶æŒ‰æ—¶é—´çª—å£æ’åºï¼Œç„¶åå°†ç»“æœè¾“å‡ºåˆ°æ§åˆ¶å°ã€‚

<font color=red>**è”ç³»ï¼š**</font>a.pyç”Ÿæˆçš„æ¨¡æ‹Ÿè´­ä¹°è¡Œä¸ºæ•°æ®æ˜¯b.pyçš„è¾“å…¥æ•°æ®æºã€‚a.pyç”Ÿæˆçš„ JSON æ–‡ä»¶åŒ…å«äº†è´­ä¹°è¡Œä¸ºçš„æ¨¡æ‹Ÿæ•°æ®ï¼Œè€Œb.pyåˆ™é€šè¿‡ Spark Structured Streaming è¯»å–è¿™äº› JSON æ–‡ä»¶ï¼Œå¹¶å®æ—¶å¤„ç†ç»Ÿè®¡è´­ä¹°è¡Œä¸ºæ•°æ®ï¼Œæœ€ç»ˆå°†ç»“æœè¾“å‡ºåˆ°æ§åˆ¶å°ã€‚

å¦‚æœä½ å…ˆæ‰§è¡Œa.pyï¼Œç”Ÿæˆäº†è´­ä¹°è¡Œä¸ºçš„æ¨¡æ‹Ÿæ•°æ®ï¼Œç„¶åå†æ‰§è¡Œb.pyï¼Œå®ƒå°†ä¼šä»a.pyç”Ÿæˆçš„ç›®å½•ä¸­è¯»å–æ•°æ®ï¼Œå¹¶è¿›è¡Œå®æ—¶ç»Ÿè®¡è´­ä¹°è¡Œä¸ºæ•°æ®ã€‚è¿™æ ·ï¼Œä½ å°±å¯ä»¥é€šè¿‡å®æ—¶ç›‘æ§æ§åˆ¶å°è¾“å‡ºï¼Œäº†è§£æ¯ä¸ªåœ°åŒºåœ¨ä¸€åˆ†é’Ÿå†…çš„è´­ä¹°æƒ…å†µï¼Œä»è€Œè¿›è¡Œå®æ—¶çš„ä¸šåŠ¡åˆ†ææˆ–ç›‘æ§ã€‚

## 3.2 Kafkaæº

[Kafka](https://blog.csdn.net/qq_67822268/article/details/138626412) æºçš„[é€‰é¡¹](https://spark.apache.org/docs/3.2.0/structured-streaming-kafka-integration.html#creating-a-kafka-source-for-batch-queries)ï¼ˆoptionï¼‰åŒ…æ‹¬å¦‚ä¸‹å‡ ä¸ª:

- assignï¼šæŒ‡å®šæ‰€æ¶ˆè´¹çš„Kafkaä¸»é¢˜å’Œåˆ†åŒºã€‚
- subscribeï¼šè®¢é˜…çš„Kafkaä¸»é¢˜ï¼Œä¸ºé€—å·åˆ†éš”çš„ä¸»é¢˜åˆ—è¡¨ã€‚
- subscribePatternï¼šè®¢é˜…çš„Kafkaä¸»é¢˜æ­£åˆ™è¡¨è¾¾å¼ï¼Œå¯åŒ¹é…å¤šä¸ªä¸»é¢˜ã€‚
- kafka.bootstrap.serversï¼šKafkaæœåŠ¡å™¨çš„åˆ—è¡¨ï¼Œé€—å·åˆ†éš”çš„â€œhostï¼športâ€åˆ—è¡¨ã€‚
- startingOffsetsï¼šèµ·å§‹ä½ç½®åç§»é‡ã€‚
- endingOffsetsï¼šç»“æŸä½ç½®åç§»é‡ã€‚
- failOnDataLossï¼šå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦åœ¨Kafka æ•°æ®å¯èƒ½ä¸¢å¤±æ—¶ï¼ˆä¸»é¢˜è¢«åˆ é™¤æˆ–ä½ç½®åç§»é‡è¶…å‡ºèŒƒå›´ç­‰ï¼‰è§¦å‘æµè®¡ç®—å¤±è´¥ã€‚ä¸€èˆ¬åº”å½“ç¦æ­¢ï¼Œä»¥å…è¯¯æŠ¥ã€‚

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%894917bc37f94a7b4c8c973b783d8dfe4d.png)

å®ä¾‹ï¼šä½¿ç”¨ç”Ÿäº§è€…ç¨‹åºæ¯0.1ç§’ç”Ÿæˆä¸€ä¸ªåŒ…å«2ä¸ªå­—æ¯çš„å•è¯ï¼Œå¹¶å†™å…¥Kafkaçš„åç§°ä¸ºâ€œwordcount-topicâ€çš„ä¸»é¢˜ï¼ˆTopicï¼‰å†…ã€‚Sparkçš„æ¶ˆè´¹è€…ç¨‹åºé€šè¿‡è®¢é˜…wordcount-topicï¼Œä¼šæºæºä¸æ–­æ”¶åˆ°å•è¯ï¼Œå¹¶ä¸”æ¯éš”8ç§’é’Ÿå¯¹æ”¶åˆ°çš„å•è¯è¿›è¡Œä¸€æ¬¡è¯é¢‘ç»Ÿè®¡ï¼ŒæŠŠç»Ÿè®¡ç»“æœè¾“å‡ºåˆ°Kafkaçš„ä¸»é¢˜wordcount-result-topicå†…ï¼ŒåŒæ—¶ï¼Œé€šè¿‡2ä¸ªç›‘æ§ç¨‹åºæ£€æŸ¥Sparkå¤„ç†çš„è¾“å…¥å’Œè¾“å‡ºç»“æœã€‚

### ï¼ˆ1ï¼‰å¯åŠ¨Kafka

æ–°å»ºä¸€ä¸ªç»ˆç«¯ï¼ˆè®°ä½œâ€œZookeeperç»ˆç«¯â€ï¼‰ï¼Œè¾“å…¥ä¸‹é¢å‘½ä»¤å¯åŠ¨ZookeeperæœåŠ¡ï¼ˆ<font color=red>ä¸è¦å…³é—­</font>è¿™ä¸ªç»ˆç«¯çª—å£ï¼Œä¸€æ—¦å…³é—­ï¼ŒZookeeperæœåŠ¡å°±åœæ­¢äº†ï¼‰ï¼š

```bash
cd /usr/local/kafka
./bin/zookeeper-server-start.sh config/zookeeper.properties
```

å¦å¤–æ‰“å¼€ç¬¬äºŒä¸ªç»ˆç«¯ï¼ˆè®°ä½œâ€œKafkaç»ˆç«¯â€ï¼‰ï¼Œç„¶åè¾“å…¥ä¸‹é¢å‘½ä»¤å¯åŠ¨KafkaæœåŠ¡ï¼ˆ<font color=red>ä¸è¦å…³é—­</font>è¿™ä¸ªç»ˆç«¯çª—å£ï¼Œä¸€æ—¦å…³é—­ï¼ŒKafkaæœåŠ¡å°±åœæ­¢äº†ï¼‰ï¼š

```bash
cd /usr/local/kafka
./bin/kafka-server-start.sh config/server.properties
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89ed1f76281f9725e615b0b9ff5a96a2f1.png)

å†æ–°å¼€ä¸€ä¸ªç»ˆç«¯ï¼ˆè®°ä½œâ€œç›‘æ§è¾“å…¥ç»ˆç«¯â€ï¼‰ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ç›‘æ§Kafkaæ”¶åˆ°çš„æ–‡æœ¬ï¼š

```bash
cd /usr/local/kafka
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic wordcount-topic
```

å†æ–°å¼€ä¸€ä¸ªç»ˆç«¯ï¼ˆè®°ä½œâ€œç›‘æ§è¾“å‡ºç»ˆç«¯â€ï¼‰ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ç›‘æ§è¾“å‡ºçš„ç»“æœæ–‡æœ¬ï¼š

```bash
cd /usr/local/kafka
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic wordcount-result-topic
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89291f74025ac5c95f5b6c373d79bee79e.png)

### ï¼ˆ2ï¼‰ç¼–å†™ç”Ÿäº§è€…ï¼ˆProducerï¼‰ç¨‹åº

åœ¨/home/hadoop/sparksj/mycode/structured/kafkasourceç›®å½•ä¸‹åˆ›å»ºå¹¶ç¼–è¾‘spark_ss_kafka_producer.pyæ–‡ä»¶ï¼š

```bash
cd /home/hadoop/sparksj/mycode/structured/kafkasource
vim spark_ss_kafka_producer.py
```

```python
import string
import random
import time
from kafka import KafkaProducer

# å¯¼å…¥æ‰€éœ€çš„åº“

if __name__ == "__main__":
    # ç¨‹åºçš„å…¥å£ç‚¹

    # åˆ›å»ºä¸€ä¸ª Kafka ç”Ÿäº§è€…ï¼ŒæŒ‡å®š Kafka æœåŠ¡å™¨çš„åœ°å€
    producer = KafkaProducer(bootstrap_servers=['localhost:9092'])

    while True:
        # è¿›å…¥æ— é™å¾ªç¯ï¼Œä¸æ–­ç”Ÿæˆå¹¶å‘é€æ¶ˆæ¯

        # ç”Ÿæˆä¸¤ä¸ªéšæœºå°å†™å­—æ¯ç»„æˆçš„å­—ç¬¦ä¸²
        s2 = (random.choice(string.ascii_lowercase) for _ in range(2))
        word = ''.join(s2)

        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„
        value = bytearray(word, 'utf-8')

        # å‘é€æ¶ˆæ¯åˆ°åä¸º 'wordcount-topic' çš„ Kafka ä¸»é¢˜
        # å¹¶è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º 10 ç§’
        producer.send('wordcount-topic', value=value).get(timeout=10)

        # ä¼‘çœ  0.1 ç§’ï¼Œç„¶åç»§ç»­å¾ªç¯
        time.sleep(0.1)
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%8977fdce276e258b2c905872ec2d32a267.png)

### ï¼ˆ3ï¼‰å®‰è£…Python3çš„Kafkaæ”¯æŒ

åœ¨è¿è¡Œç”Ÿäº§è€…ç¨‹åºä¹‹å‰è¦å…ˆå®‰è£…[kafka-python](https://kafka-python.readthedocs.io/en/master/install.html)ï¼Œå¦‚æœè¯»è€…ä¹‹å‰<font color=red>å·²ç»å®‰è£…å¯è·³è¿‡æ­¤å°èŠ‚</font>ã€‚

1.é¦–å…ˆç¡®è®¤æœ‰æ²¡æœ‰å®‰è£…pip3ï¼Œå¦‚æœæ²¡æœ‰ï¼Œä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å®‰è£…ï¼ˆç¬”è€…å·²ç»å®‰è£…ï¼Œä¸åœ¨æ¼”ç¤ºï¼‰ï¼š

```bash
sudo apt-get install pip3
```

2.å®‰è£…kafka-pythonæ¨¡å—ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š

```bash
sudo pip3 install kafka-python
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%898604e64ac3ea12540415474f1fab25d1.png)

å®‰è£…å®Œæˆåå¯ä»¥ä½¿ç”¨'<font color=red>pip3 list</font>'å‘½ä»¤åˆ—å‡ºå½“å‰ Python ç¯å¢ƒä¸­å·²å®‰è£…çš„æ‰€æœ‰ Python åŒ…ï¼ŒæŸ¥çœ‹æ˜¯å¦æœ‰kafka-pythonåŒ…ï¼š

```bash
pip3 list
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%895ab19e59eb7cad523041bbb42608c5d7.png)

å¯ä»¥çœ‹åˆ°å­˜åœ¨kafka-pythonåŒ…ï¼Œç‰ˆæœ¬ä¸º2.0.2

### ï¼ˆ4ï¼‰è¿è¡Œç”Ÿäº§è€…ç¨‹åº

æ–°å»ºä¸€ä¸ªç»ˆç«¯ï¼Œåœ¨ç»ˆç«¯ä¸­æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤è¿è¡Œç”Ÿäº§è€…ç¨‹åºï¼š

```bash
cd /home/hadoop/sparksj/mycode/structured/kafkasource
python3 spark_ss_kafka_producer.py
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%895340206fa64ad8d1afa416b658fb6352.png)

ç”Ÿäº§è€…ç¨‹åºæ‰§è¡Œä»¥åï¼Œåœ¨â€œ<font color=red>**ç›‘æ§è¾“å…¥ç»ˆç«¯**</font>â€çš„çª—å£å†…å°±å¯ä»¥çœ‹åˆ°æŒç»­è¾“å‡ºåŒ…å«2ä¸ªå­—æ¯çš„å•è¯ã€‚ç¨‹åºä¼šç”Ÿæˆéšæœºå­—ç¬¦ä¸²å¹¶å°†å…¶å‘é€åˆ° Kafka ä¸»é¢˜ä¸­ï¼Œä¸»é¢˜æ¥æ”¶åˆ°éšæœºå­—ç¬¦ä¸²åä¼šå±•ç¤ºåˆ°ç»ˆç«¯ã€‚

**è§£é‡Šï¼š**

æ‰§è¡Œï¼ˆ1ï¼‰ä¸­çš„å‘½ä»¤ `./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic wordcount-topic` ä¼šå¯åŠ¨ Kafka çš„æ§åˆ¶å°æ¶ˆè´¹è€…ï¼Œç”¨äºä»æŒ‡å®šçš„ Kafka ä¸»é¢˜ä¸­è¯»å–æ¶ˆæ¯å¹¶å°†å…¶è¾“å‡ºåˆ°æ§åˆ¶å°ä¸Šã€‚

è€Œç”Ÿäº§è€…ç¨‹åºæ˜¯ä¸€ä¸ªç®€å•çš„ Kafka ç”Ÿäº§è€…ç¤ºä¾‹ï¼Œç”¨äºç”Ÿæˆéšæœºå­—ç¬¦ä¸²å¹¶å°†å…¶å‘é€åˆ°åä¸º 'wordcount-topic' çš„ Kafka ä¸»é¢˜ä¸­ã€‚

å½“å¯åŠ¨ Kafka çš„æ§åˆ¶å°æ¶ˆè´¹è€…åŒæ—¶è¿è¡Œç”Ÿäº§è€…ç¨‹åºæ—¶ï¼Œç”Ÿäº§è€…ä»£ç ä¼šä¸æ–­åœ°ç”Ÿæˆéšæœºå­—ç¬¦ä¸²å¹¶å‘é€åˆ° 'wordcount-topic' ä¸»é¢˜ï¼Œè€Œæ§åˆ¶å°æ¶ˆè´¹è€…åˆ™ä¼šä»è¯¥ä¸»é¢˜ä¸­è¯»å–å¹¶æ˜¾ç¤ºè¿™äº›æ¶ˆæ¯ã€‚å› æ­¤ï¼Œä¼šå¯¼è‡´ç”Ÿäº§è€…ä¸æ–­åœ°ç”Ÿæˆæ¶ˆæ¯ï¼Œå¹¶ä¸”æ§åˆ¶å°æ¶ˆè´¹è€…ä¼šå³æ—¶åœ°è¾“å‡ºè¿™äº›æ¶ˆæ¯ï¼Œä»è€Œå®ç°äº†æ¶ˆæ¯çš„ç”Ÿäº§å’Œæ¶ˆè´¹è¿‡ç¨‹ã€‚

ä¸Šè¿°ç”¨äºæµ‹è¯• Kafka ç¯å¢ƒçš„æ­å»ºå’Œæ¶ˆæ¯ä¼ é€’çš„è¿‡ç¨‹ï¼Œä»¥ç¡®ä¿ç”Ÿäº§è€…èƒ½å¤ŸæˆåŠŸåœ°å°†æ¶ˆæ¯å‘é€åˆ°æŒ‡å®šçš„ä¸»é¢˜ï¼ŒåŒæ—¶æ¶ˆè´¹è€…èƒ½å¤Ÿä»è¯¥ä¸»é¢˜ä¸­æ¥æ”¶å¹¶å¤„ç†è¿™äº›æ¶ˆæ¯ã€‚

### ï¼ˆ5ï¼‰ç¼–å†™å¹¶è¿è¡Œæ¶ˆè´¹è€…ï¼ˆConsumerï¼‰ç¨‹åº

åŒæ ·ï¼Œåœ¨/home/hadoop/sparksj/mycode/structured/kafkasourceç›®å½•ä¸‹åˆ›å»ºå¹¶ç¼–è¾‘spark_ss_kafka_consumer.pyæ–‡ä»¶ï¼š

```bash
cd /home/hadoop/sparksj/mycode/structured/kafkasource
vim spark_ss_kafka_consumer.py
```

```python
from pyspark.sql import SparkSession

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    # åˆ›å»ºä¸€ä¸ª SparkSession
    spark = SparkSession \
        .builder \
        .appName("StructuredKafkaWordCount") \  # è®¾ç½®åº”ç”¨ç¨‹åºåç§°
        .getOrCreate()  # è·å–æˆ–åˆ›å»º SparkSession å®ä¾‹

    # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºWARNï¼Œé¿å…è¿‡å¤šçš„è¾“å‡ºä¿¡æ¯
    spark.sparkContext.setLogLevel('WARN')

    # ä» Kafka ä¸»é¢˜ä¸­è¯»å–æ•°æ®
    lines = spark \
        .readStream \  # åˆ›å»ºä¸€ä¸ªæµå¼DataFrame
        .format("kafka") \  # æŒ‡å®šæ•°æ®æºæ ¼å¼ä¸ºKafka
        .option("kafka.bootstrap.servers", "localhost:9092") \  # è®¾ç½®Kafkaé›†ç¾¤çš„åœ°å€
        .option("subscribe", 'wordcount-topic') \  # è®¢é˜…åä¸º'wordcount-topic'çš„ä¸»é¢˜
        .load() \  # ä»Kafkaä¸»é¢˜ä¸­åŠ è½½æ•°æ®
        .selectExpr("CAST(value AS STRING)")  # å°†æ¶ˆæ¯å†…å®¹è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼

    # å¯¹æ•°æ®è¿›è¡Œèšåˆç»Ÿè®¡
    wordCounts = lines.groupBy("value").count()

    # å°†ç»“æœå†™å…¥åˆ°å¦ä¸€ä¸ª Kafka ä¸»é¢˜ä¸­
    query = wordCounts \
        .selectExpr("CAST(value AS STRING) as key", "CONCAT(CAST(value AS STRING), ':', CAST(count AS STRING)) as value") \  # æ ¼å¼åŒ–è¾“å‡ºçš„keyå’Œvalue
        .writeStream \  # åˆ›å»ºä¸€ä¸ªæµå¼DataFrame
        .outputMode("complete") \  # å®šä¹‰è¾“å‡ºæ¨¡å¼ä¸ºcomplete
        .format("kafka") \  # æŒ‡å®šè¾“å‡ºæ•°æ®æºæ ¼å¼ä¸ºKafka
        .option("kafka.bootstrap.servers", "localhost:9092") \  # è®¾ç½®Kafkaé›†ç¾¤çš„åœ°å€
        .option("topic", "wordcount-result-topic") \  # æŒ‡å®šè¾“å‡ºçš„Kafkaä¸»é¢˜
        .option("checkpointLocation", "file:///tmp/kafka-sink-cp") \  # è®¾ç½®æ£€æŸ¥ç‚¹ç›®å½•
        .trigger(processingTime="8 seconds") \  # å®šæ—¶è§¦å‘ï¼Œæ¯8ç§’å¤„ç†ä¸€æ¬¡æ•°æ®
        .start()  # å¯åŠ¨æµå¼æŸ¥è¯¢

    query.awaitTermination()  # ç­‰å¾…æµå¼æŸ¥è¯¢ç»ˆæ­¢
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%8932aa60e468596d5177226ee6ee53ac65.png)

åœ¨è¿è¡Œæ¶ˆè´¹è€…ç¨‹åºï¼ˆå³spark_ss_kafka_consumer.pyï¼‰æ—¶ï¼Œè¯·<font color=red>ç¡®ä¿kafkaæˆåŠŸå¯åŠ¨ï¼Œç›‘æ§è¾“å…¥ç»ˆç«¯ä¸ç›‘æ§è¾“å‡ºç«¯æˆåŠŸå¯åŠ¨ï¼Œç”Ÿäº§è€…ç¨‹åºæˆåŠŸå¯åŠ¨</font>ï¼ˆè‹¥é‡‡ç”¨æ–¹å¼ä¸€å¯åŠ¨æ¶ˆè´¹è€…ç¨‹åºåˆ™å¯ä»¥ç­‰ä¼šç”Ÿäº§è€…ç¨‹åºï¼Œå› ä¸ºjaråŒ…ä¸‹è½½å¯èƒ½æ—¶é—´è¿‡é•¿ï¼Œé•¿æ—¶é—´ç”Ÿäº§è€…ç¨‹åºä¼šäº§ç”Ÿå¤§é‡çš„æ•°æ®ï¼›è‹¥é‡‡ç”¨æ–¹å¼äºŒå¯åŠ¨æ¶ˆè´¹è€…ç¨‹åºåˆ™ç¡®ä¿å¯åŠ¨æ¶ˆè´¹è€…ç¨‹åºå‰å¯åŠ¨ç”Ÿäº§è€…ç¨‹åºï¼Œæ­£å¦‚ä¸‹æ–¹è§†é¢‘æ‰€ç¤ºï¼‰

è¿è¡Œæ¶ˆè´¹è€…ç¨‹åºå¯ä»¥æœ‰<font color=red>ä¸¤ç§</font>æ–¹å¼ï¼š

#### æ–¹å¼ä¸€

```bash
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0 spark_ss_kafka_consumer.py
```

ä½¿ç”¨äº†`--packages`å‚æ•°ï¼ŒæŒ‡å®šäº†è¦ä»[Mavenä»“åº“](https://mvnrepository.com/)ä¸­ä¸‹è½½å¹¶åŒ…å«çš„ä¾èµ–åŒ…ï¼Œå…¶ä¸­`org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0`æ˜¯è¦æ·»åŠ çš„Kafkaç›¸å…³ä¾èµ–ã€‚

ä½œç”¨ï¼šåœ¨è¿è¡Œåº”ç”¨ç¨‹åºæ—¶åŠ¨æ€ä¸‹è½½Kafkaç›¸å…³çš„ä¾èµ–åŒ…ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°ç±»è·¯å¾„ä¸­ï¼Œä»¥ä¾¿åº”ç”¨ç¨‹åºèƒ½å¤Ÿè®¿é—®è¿™äº›ä¾èµ–

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%8932a9d71702734d9b62bbc2453d54c970.png)

è¿è¡Œåä¼šè§£æåŒ…ä¾èµ–å¹¶ä»[Mavenä¸­å¿ƒä»“åº“](https://repo1.maven.org/maven2/)ä¸‹è½½æ‰€éœ€çš„JARåŒ…ï¼Œä¸‹è½½å®Œæˆåè¿›è¡Œè¿è¡Œï¼Œä½†è¿™ç§æ–¹æ³•ä¾èµ–äºè‡ªèº«ç½‘ç»œç¯å¢ƒï¼Œç¬”è€…è¿™è¾¹å› ä¸ºæ˜¯æ ¡å›­ç½‘ï¼Œè´¼æ…¢ï¼Œæ•…ä¸å†å±•ç¤ºè¿è¡Œç»“æœ

#### æ–¹å¼äºŒ

åœ¨æ‰§è¡Œä¸‹åˆ—ä»£ç ä¹‹å‰ï¼Œéœ€è¦ä¸‹è½½spark-sql-kafka-0-10_2.12-3.2.0.jarã€kafka-clients-2.6.0.jarã€commons-pool2-2.9.0.jarå’Œspark-token-provider-kafka-0-10_2.12-3.2.0.jaræ–‡ä»¶ï¼ˆç¬”è€…sparkç‰ˆæœ¬ä¸ºspark 3.2.0ã€kafkaç‰ˆæœ¬ä¸ºkafka_2.12-2.6.0ï¼Œè¯»è€…è¯·æ ¹æ®è‡ªå·±çš„ç‰ˆæœ¬è°ƒæ•´jarç‰ˆæœ¬çš„ä¸‹è½½ï¼‰ï¼Œå°†å…¶**<font color=red>æ”¾åˆ°â€œ/usr/local/spark/jarsâ€ç›®å½•ä¸‹</font>**ï¼Œç°é™„ä¸Šä¸‹è½½åœ°å€:

[spark-sql-kafka-0-10_2.12-3.2.0.jaræ–‡ä»¶ä¸‹è½½é¡µé¢](https://mvnrepository.com/artifact/org.apache.spark/spark-sql-kafka-0-10_2.12/3.2.0)
[kafka-clients-2.6.0.jaræ–‡ä»¶ä¸‹è½½é¡µé¢](https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients/2.6.0)
[commons-pool2-2.9.0.jaræ–‡ä»¶ä¸‹è½½é¡µé¢](https://mvnrepository.com/artifact/org.apache.commons/commons-pool2/2.9.0)
[spark-token-provider-kafka-0-10_2.12-3.2.0.jaræ–‡ä»¶ä¸‹è½½é¡µé¢](https://mvnrepository.com/artifact/org.apache.spark/spark-token-provider-kafka-0-10_2.12/3.2.0)



è‹¥ä¸Šè¿°ç½‘ç«™ä¸èƒ½æ‰“å¼€ï¼Œå¯å°è¯•ç”µè„‘è¿æ¥æ‰‹æœºçƒ­ç‚¹æˆ–ä½¿ç”¨å¦‚ä¸‹ç½‘å€è¿›è¡Œä¸‹è½½ï¼š

é“¾æ¥ï¼š[https://pan.baidu.com/s/121zVsgc4muSt9rgCWnJZmw](https://pan.baidu.com/s/121zVsgc4muSt9rgCWnJZmw)

æå–ç ï¼šwkk6

[spark-sql-kafka-0-10_2.12-3.2.0.jaræ–‡ä»¶ä¸‹è½½é¡µé¢](https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.2.0/)

[kafka-clients-2.6.0.jaræ–‡ä»¶ä¸‹è½½é¡µé¢](https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.6.0/)

[commons-pool2-2.9.0.jaræ–‡ä»¶ä¸‹è½½é¡µé¢](https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.9.0/)

[spark-token-provider-kafka-0-10_2.12-3.2.0.jaræ–‡ä»¶ä¸‹è½½é¡µé¢](https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.2.0/)



ä¸‹åˆ—ä¸¤æ®µä»£ç äºŒé€‰ä¸€æ‰§è¡Œï¼š

```bash
spark-submit --jars "/usr/local/spark/jars/*" spark_ss_kafka_consumer.py
```

æˆ–

```bash
spark-submit --jars "/usr/local/kafka/libs/*:/usr/local/spark/jars/*" spark_ss_kafka_consumer.py
```

ä½¿ç”¨äº†`--jars`å‚æ•°ï¼ŒæŒ‡å®šäº†è¦åŒ…å«åœ¨ç±»è·¯å¾„ä¸­çš„å¤–éƒ¨JARåŒ…çš„è·¯å¾„

`/usr/local/kafka/libs/*`å’Œ`/usr/local/spark/jars/*`æ˜¯è¦åŒ…å«çš„Kafkaå’ŒSparkç›¸å…³çš„JARåŒ…çš„è·¯å¾„

ä½œç”¨ï¼šæ˜¾å¼åœ°æŒ‡å®šè¦åŒ…å«åœ¨ç±»è·¯å¾„ä¸­çš„JARåŒ…ï¼Œè€Œä¸æ˜¯åŠ¨æ€ä¸‹è½½ä¾èµ–



è¿è¡Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆåŒæ ·å¯ä»¥è®¾ç½®è¾“å‡ºæ—¥å¿—çº§åˆ«æ¥æ§åˆ¶æ—¥å¿—çš„è¾“å‡ºï¼Œåœ¨æ­¤ä¸å†èµ˜è¿°ï¼‰ï¼š

è§†é¢‘ç‰ˆï¼š

<video src="https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89structuredstreaming-kafka.mp4"></video>

structured streamingä½¿ç”¨kafkaæº

GIFç‰ˆï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89aa420ca37f004af35fe44de3ab36ed2e.gif)

å˜¿å˜¿å˜¿ï¼Œåšä¸»<font color=red>è´´å¿ƒ</font>çš„å‡†å¤‡äº†è§†é¢‘å’ŒåŠ¨å›¾ä¸¤ä¸ªç‰ˆæœ¬ï¼Œè¯»è€…å¯æŒ‰éœ€è‡ªå–ğŸ˜

å°±éº»çƒ¦å„ä½ç‚¹ä¸ªèµå•¦~~(*/Ï‰ï¼¼*)

### æ€»ç»“

1. `./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic wordcount-topicï¼š`åœ¨ç»ˆç«¯ç›‘æ§åä¸º`wordcount-topic`çš„Kafkaä¸»é¢˜çš„è¾“å…¥ä¿¡æ¯
2. `./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic wordcount-result-topic` ï¼šåœ¨ç»ˆç«¯ç›‘æ§åä¸º`wordcount-result-topic`çš„Kafkaä¸»é¢˜çš„è¾“å‡ºä¿¡æ¯
3. `spark_ss_kafka_producer.py` ï¼šç”Ÿæˆéšæœºçš„ä¸¤ä¸ªå°å†™å­—æ¯å­—ç¬¦ä¸²ï¼Œå¹¶å°†å…¶å‘é€åˆ°`wordcount-topic`ä¸»é¢˜ä¸­
4. `spark_ss_kafka_consumer.py` ï¼šä»`wordcount-topic`ä¸»é¢˜ä¸­è¯»å–æ¶ˆæ¯ï¼Œå¯¹å•è¯è¿›è¡Œè®¡æ•°ï¼Œç„¶åå°†ç»“æœå†™å…¥`wordcount-result-topic`ä¸»é¢˜ã€‚è¯¥ç¨‹åºä¼šæŒç»­è¿è¡Œå¹¶ç­‰å¾…æ–°çš„è¾“å…¥æ¶ˆæ¯

å¦‚æœä¾æ¬¡æ‰§è¡Œäº†ä¸Šè¿°å››ä¸ªå‘½ä»¤æˆ–ä»£ç ï¼Œå¯ä»¥å¾—åˆ°ä»¥ä¸‹ç»“æœï¼š

- ç›‘æ§è¾“å…¥ç»ˆç«¯ä¼šæ˜¾ç¤ºä»`wordcount-topic`ä¸»é¢˜ä¸­æ¥æ”¶åˆ°çš„éšæœºå°å†™å­—æ¯å­—ç¬¦ä¸²
- ç›‘æ§è¾“å…¥ç»ˆç«¯ä¼šæ˜¾ç¤ºä»`wordcount-result-topic`ä¸»é¢˜ä¸­æ¥æ”¶åˆ°çš„å•è¯è®¡æ•°ç»“æœ
- ç”Ÿäº§è€…ç¨‹åºä¼šä¸æ–­åœ°ç”Ÿæˆéšæœºå­—ç¬¦ä¸²ï¼Œå¹¶å°†å…¶å‘é€åˆ°`wordcount-topic`ä¸»é¢˜
- æ¶ˆè´¹è€…ç¨‹åºä¼šæŒç»­åœ°ä»`wordcount-topic`ä¸»é¢˜ä¸­è¯»å–æ¶ˆæ¯ï¼Œå¯¹å•è¯è¿›è¡Œè®¡æ•°ï¼Œå¹¶å°†ç»“æœå†™å…¥`wordcount-result-topic`ä¸»é¢˜

å¦‚æœåªæ‰§è¡Œç¬¬ä¸€æ¡å‘½ä»¤å’Œç”Ÿäº§è€…ç¨‹åºï¼Œé‚£ä¹ˆä¼šçœ‹åˆ°ç»ˆç«¯ä¸æ–­æ‰“å°å‡ºéšæœºçš„ä¸¤ä¸ªå°å†™å­—æ¯å­—ç¬¦ä¸²ï¼Œè€Œä¸ä¼šæœ‰å•è¯è®¡æ•°æˆ–ç»“æœè¾“å‡ºã€‚

## 3.3 Socketæº

Socket æºçš„é€‰é¡¹ï¼ˆoptionï¼‰åŒ…æ‹¬å¦‚ä¸‹å‡ ä¸ªï¼š

- hostï¼šä¸»æœº IPåœ°å€æˆ–è€…åŸŸåï¼Œå¿…é¡»è®¾ç½®ã€‚
- portï¼šç«¯å£å·ï¼Œå¿…é¡»è®¾ç½®ã€‚
- includeTimestampï¼šæ˜¯å¦åœ¨æ•°æ®è¡Œå†…åŒ…å«æ—¶é—´æˆ³ã€‚ä½¿ç”¨æ—¶é—´æˆ³å¯ä»¥ç”¨æ¥æµ‹è¯•åŸºäºæ—¶é—´èšåˆçš„åŠŸèƒ½ã€‚

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%8933fcc8f121e22d35aa2b12623ebc56b0.png)

Socketæºä»ä¸€ä¸ªæœ¬åœ°æˆ–è¿œç¨‹ä¸»æœºçš„æŸä¸ªç«¯å£æœåŠ¡ä¸Šè¯»å–æ•°æ®ï¼Œæ•°æ®çš„ç¼–ç ä¸ºUTF8ã€‚å› ä¸ºSocketæºä½¿ç”¨å†…å­˜ä¿å­˜è¯»å–åˆ°çš„æ‰€æœ‰æ•°æ®ï¼Œå¹¶ä¸”è¿œç«¯æœåŠ¡ä¸èƒ½ä¿è¯æ•°æ®åœ¨å‡ºé”™åå¯ä»¥ä½¿ç”¨æ£€æŸ¥ç‚¹æˆ–è€…æŒ‡å®šå½“å‰å·²å¤„ç†çš„åç§»é‡æ¥é‡æ”¾æ•°æ®ï¼Œæ‰€ä»¥ï¼Œå®ƒæ— æ³•æä¾›ç«¯åˆ°ç«¯çš„å®¹é”™ä¿éšœã€‚Socketæºä¸€èˆ¬<font color=gree>ä»…ç”¨äºæµ‹è¯•æˆ–å­¦ä¹ ç”¨é€”</font>ã€‚

å®ä¾‹å¯å‚è€ƒ[äºŒã€ç¼–å†™Structured Streamingç¨‹åºçš„åŸºæœ¬æ­¥éª¤](#äºŒç¼–å†™structured-streamingç¨‹åºçš„åŸºæœ¬æ­¥éª¤)

## 3.4 Rateæº

Rateæºæ˜¯ä¸€ç§ç”¨äºç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®æµçš„å†…ç½®æ•°æ®æºã€‚

Rateæºå¯æ¯ç§’ç”Ÿæˆç‰¹å®šä¸ªæ•°çš„æ•°æ®è¡Œï¼Œæ¯ä¸ªæ•°æ®è¡ŒåŒ…æ‹¬æ—¶é—´æˆ³å’Œå€¼å­—æ®µã€‚æ—¶é—´æˆ³æ˜¯æ¶ˆæ¯å‘é€çš„æ—¶é—´ï¼Œå€¼æ˜¯ä»å¼€å§‹åˆ°å½“å‰æ¶ˆæ¯å‘é€çš„æ€»ä¸ªæ•°ï¼Œä»0å¼€å§‹ã€‚Rateæºä¸€èˆ¬ç”¨æ¥ä½œä¸ºè°ƒè¯•æˆ–æ€§èƒ½åŸºå‡†æµ‹è¯•ã€‚

Rate æºçš„é€‰é¡¹ï¼ˆoptionï¼‰åŒ…æ‹¬å¦‚ä¸‹å‡ ä¸ªï¼š

- rowsPerSecondï¼šæ¯ç§’äº§ç”Ÿå¤šå°‘è¡Œæ•°æ®ï¼Œé»˜è®¤ä¸º1ã€‚
- rampUpTimeï¼šç”Ÿæˆé€Ÿåº¦è¾¾åˆ°rowsPerSecond éœ€è¦å¤šå°‘å¯åŠ¨æ—¶é—´ï¼Œä½¿ç”¨æ¯”ç§’æ›´ç²¾ç»†çš„ç²’åº¦å°†ä¼šè¢«æˆªæ–­ä¸ºæ•´æ•°ç§’ï¼Œé»˜è®¤ä¸º0ç§’ã€‚
- numPartitionsï¼šä½¿ç”¨çš„åˆ†åŒºæ•°ï¼Œé»˜è®¤ä¸ºSparkçš„é»˜è®¤åˆ†åŒºæ•°ã€‚

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89a4367326af6f2e6879e05ad3ef0b6992.png)

Rate æºä¼šå°½å¯èƒ½åœ°ä½¿æ¯ç§’ç”Ÿæˆçš„æ•°æ®é‡è¾¾åˆ°rowsPerSecondï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´numPartitionsä»¥å°½å¿«è¾¾åˆ°æ‰€éœ€çš„é€Ÿåº¦ã€‚è¿™å‡ ä¸ªå‚æ•°çš„ä½œç”¨ç±»ä¼¼ä¸€è¾†æ±½è½¦ä»0åŠ é€Ÿåˆ°100åƒç±³/å°æ—¶å¹¶ä»¥100åƒç±³/å°æ—¶è¿›è¡Œå·¡èˆªçš„è¿‡ç¨‹ï¼Œé€šè¿‡å¢åŠ â€œé©¬åŠ›â€ï¼ˆnumPartitionsï¼‰ï¼Œå¯ä»¥ä½¿å¾—åŠ é€Ÿæ—¶é—´ï¼ˆrampUpTimeï¼‰æ›´çŸ­ã€‚
 å¯ä»¥ç”¨ä¸€å°æ®µä»£ç æ¥è§‚å¯Ÿ Rate æºçš„æ•°æ®è¡Œæ ¼å¼å’Œç”Ÿæˆæ•°æ®çš„å†…å®¹ã€‚

å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç æ¥è§‚å¯ŸRateæºçš„æ•°æ®è¡Œæ ¼å¼å’Œç”Ÿæˆæ•°æ®çš„å†…å®¹ï¼š

åœ¨/home/hadoop/sparksj/mycode/structured/ratesourceç›®å½•ä¸‹æ–°å»ºæ–‡ä»¶spark_ss_rate.pyï¼š

```python
from pyspark.sql import SparkSession

if __name__ == "__main__":
    # åˆ›å»ºä¸€ä¸ª SparkSession å¯¹è±¡
    spark = SparkSession \
        .builder \
        .appName("TestRateStreamSource") \
        .getOrCreate()

    # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºWARN
    spark.sparkContext.setLogLevel('WARN')

    # ä» Rate source ä¸­è¯»å–æ•°æ®æµ
    lines = spark \
        .readStream \
        .format("rate") \
        .option('rowsPerSecond', 5) \
        .load()
    
    # æ‰“å°å‡ºæ•°æ®æµçš„ schema
    print(lines.schema)

    # å°†æ•°æ®æµå†™å…¥æ§åˆ¶å°
    query = lines \
        .writeStream \
        .outputMode("update") \
        .format("console") \
        .option('truncate', 'false') \
        .start()

    # ç­‰å¾…æµå¤„ç†çš„ç»ˆæ­¢
    query.awaitTermination()
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%892b94bfb037a5c98162c13c584acad5e2.png)

åœ¨Linuxç»ˆç«¯æ‰§è¡Œspark_ss_rate.pyï¼š

```bash
cd /home/hadoop/sparksj/mycode/structured/ratesource
spark-submit spark_ss_rate.py
```

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%89ebb411270275e785188f261618d16d93.png)

è¾“å‡ºçš„ç¬¬ä¸€è¡Œï¼ˆå³ä¸Šå›¾çº¢æ¡†æ¡†ä½çš„é‚£ä¸€è¡Œï¼‰StruckTypeå°±æ˜¯print(lines.schema)è¾“å‡ºçš„æ•°æ®è¡Œçš„æ ¼å¼ã€‚

å½“è¿è¡Œè¿™æ®µä»£ç æ—¶ï¼Œå®ƒä¼šç”Ÿæˆæ¨¡æ‹Ÿçš„è¿ç»­æ•°æ®æµï¼Œå¹¶å°†å…¶å†™å…¥æ§åˆ¶å°è¿›è¡Œæ˜¾ç¤ºã€‚è¾“å‡ºç»“æœä¼šåŒ…å«æ—¶é—´æˆ³å’Œç”Ÿæˆçš„å€¼ã€‚åŒæ—¶ï¼Œç¨‹åºä¼šæŒç»­è¿è¡Œï¼Œç›´åˆ°æ‰‹åŠ¨ç»ˆæ­¢æˆ–å‡ºç°å¼‚å¸¸ã€‚

------

åŒ[ï¼ˆ4ï¼‰å¤„ç†è­¦å‘Š](#4å¤„ç†è­¦å‘Š)ï¼Œä¹Ÿå¯ä»¥è®¾ç½®æ—¥å¿—è¾“å‡ºç­‰çº§æ¥å¿½ç•¥è­¦å‘Šï¼Œå°†spark.sparkContext.setLogLevel('WARN')æ”¹ä¸ºspark.sparkContext.setLogLevel('ERROR')ï¼š

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%8951add7792dd73850dbc060ceb04341f3.png)

å†æ¬¡æ‰§è¡Œç»“æœå¦‚ä¸‹ï¼Œå¹²å‡€æ•´æ´~~(âÂ´â—¡`â)~~â˜†*: .ï½¡. o(â‰§â–½â‰¦)o .ï½¡.:*â˜†

![img](https://github.com/wkkwky/wkkwky.github.io/tree/master/images/2024-06-01-%E3%80%90%E7%AC%94%E8%AE%B0%E3%80%91Sturctured%20Streaming%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88Python%E7%89%88%EF%BC%899eff3e9c2eabeff7fa8492519b314545.png)

